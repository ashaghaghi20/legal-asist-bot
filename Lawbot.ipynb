{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaghaghi20/legal-asist-bot/blob/main/Lawbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tufg7EvF7qV5",
        "outputId": "f8f7d09d-05a1-4e6e-e1ca-c93e0059fbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting whisper-openai\n",
            "  Downloading whisper_openai-1.0.0-py3-none-any.whl.metadata (480 bytes)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.1.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (10.8.0)\n",
            "Collecting ffmpeg-python==0.2.0 (from whisper-openai)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python==0.2.0->whisper-openai) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Downloading python_telegram_bot-22.5-py3-none-any.whl (730 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.0/731.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading whisper_openai-1.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.1.0-py3-none-any.whl (964 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m964.9/964.9 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, ffmpeg-python, python-telegram-bot, openai, transformers, whisper-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-2.1.0 python-telegram-bot-22.5 pytube-15.0.0 transformers-4.57.0 whisper-openai-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## Ù†ØµØ¨ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§\n",
        "# Ø§Ø¬Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³Ù„ÙˆÙ„ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø²Ù…Ø§Ù† Ø¨Ø¨Ø±Ø¯.\n",
        "\n",
        "# %%\n",
        "# Install necessary libraries including nest-asyncio and upgrade conflicting ones for dependency resolution\n",
        "!pip install --upgrade python-telegram-bot nest-asyncio whisper-openai pytube openai python-dotenv sentence-transformers transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ff689d5"
      },
      "outputs": [],
      "source": [
        "# Removed redundant cell execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530b8678"
      },
      "source": [
        "## Ø§Ù†Ø¬Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹\n",
        "\n",
        "### Subtask:\n",
        "Ø±Ø¨Ø§Øª Ù‡Ù…â€ŒØ§Ú©Ù†ÙˆÙ† ÙØ¹Ø§Ù„ Ø§Ø³Øª. Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ ØªØ³Øª Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ø´Ø§Ù…Ù„ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†ØŒ Ø§Ø±Ø³Ø§Ù„ Ù…ØªÙˆÙ† Ù…Ø®ØªÙ„Ù (Ø­Ù‚ÙˆÙ‚ÛŒ Ùˆ ØºÛŒØ±Ø­Ù‚ÙˆÙ‚ÛŒ) Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ†ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø±Ø¨Ø§Øª Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ù†ÙˆØŒ Ùˆ ØªØ³Øª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª. Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø±Ø§ Ø«Ø¨Øª Ùˆ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù…Ø´Ú©Ù„ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1e5e34f19d884885a3c38977b0705a7a",
            "1f1241acb0234a6486bc36922fcc90a8",
            "ca4a185f8c4943979be80ec31613dce9",
            "9eb60c187a3045c4a88734258fb01f04",
            "c936a30f62e34fb1b8977f2f0cb4660d",
            "7af069d3fded4f7986b556b85aa4afb5",
            "2219741944524fc583db7558a6efbc42",
            "e2775aeb495f4176b4684f460256a518",
            "990218703b0b4ffbb07d148eca82d998",
            "3959ace5492242d6b29a3bf91ac7aa99",
            "833e410d4f7d4cc4982c242676e75baf",
            "a71987446a3d4206b49abcd98bb1874a",
            "95113e7ba22a442590a51dbcb009b6e2",
            "87ef098897564d628ce320e649d70e28",
            "d012be5b6b51473991fb258f41b1a264",
            "f859d1b98b124b06b298b3564a05d719",
            "993f420e78814ef399ae11ccd44e201e",
            "611d9bb671934f7795a2c52042265f35",
            "b55b5d4d87ac4e29bea6ca58749a4f12",
            "b8acba16a03b4f9db6df413afa3614bb",
            "a340bfe506e0413eba2478d11d652543",
            "792cce6a91cb4fbdb39a829168b8d77a",
            "66deb0ce078446fda52ad66ebfceb3d4",
            "993db2903cab423dbecb32a3dd4cb26c",
            "614d1d10c5fd46b5ba467603dc52026e",
            "293d45e33f7143548eccb114c799caa9",
            "0f00bb9e0d2d43cfb22f9fd4238b7092",
            "c26f0a13cb5345dabe14aa299bef296b",
            "43d440a6d0aa410d8d910238291aa1e8",
            "96f0dd17eb134f6d82ac13a948739dcb",
            "1deb5b37670b40bcb050c19b913af3c2",
            "0572e86c8da3443fa4b37e835bef21a4",
            "3cdd65b8b4944583b6b1dedf2f120eb2",
            "c1e65ecd64c946c8a02c5fcce3efb5d0",
            "79ba7084f0084958b0f2921379856899",
            "6db966099fdf4364930a3a9283a20f2a",
            "0853b2621cc44531a88d7e00417d812b",
            "0c98c5414519401a8b662f06d2757e73",
            "8b44407dc1234070874ff86dc8965f01",
            "48e7d484489f4dcd97603fe2c4b0e9e8",
            "3e6eaf8fa2ad479da8d8be9bbac1237f",
            "d67c3df01e4e4d92983f06c26560cde8",
            "63d0e946289a490fadd14a73d9735604",
            "b821ec5af006453a835f93c1bcd65292",
            "5d2107f14ad64964890916f451af86f2",
            "d45f125223504cb39b07621cfd325fd4",
            "b3cda01c19144229bb4bc0536ab7c578",
            "06eb5668fc574a0dac13f8bbdb06680f",
            "e5691d659a5049d996de42216f33ece7",
            "a5eb436a23ab40d0951a8d947634e7d1",
            "9233c7b599824142a8d2cf1810c868a7",
            "e044571c13e445409c0ae56031ba164c",
            "41ab45e72c5843f88c8ab7b1224600dd",
            "262644632c0d453f9094271f0df88dc5",
            "af3b1ab6a34c436dab24382a91bfc5cc",
            "8f507492379143e0a41317cd89d806f5",
            "a67bb6314f60489f9075e4cac75ff273",
            "3d651afbb91845ea9ac17b5fe3276d6a",
            "a4fa9c8a6038400086b1adfdd6bd2a55",
            "dc72e05be2854a19b4868432eb058e24",
            "6ffcd85dd0e94651aab6a15bafe3ee32",
            "2f13ef86f6bf446e909e5cf122d76bf5",
            "cf136179ed324817b3af35cd2c8cfb5e",
            "69103b7075e54b6a8175c4ceb8c5e903",
            "cc504f7824f346c398c69663e811872d",
            "413708a77b024c57bae6c229a59a372c",
            "341bea3430fc4eeaa943118768d58d38",
            "3a6a64b9a1274d6a803d8e57075a7d8e",
            "44763f4b1745400ba706f9afcb9a2338",
            "f9815cbf367d4f27bf0f7a8baa0a268f",
            "a1512da8a42e40c9be4aef79967d7c27",
            "a3e957510f5b4215ac60da1c8b94e0c6",
            "bd3c992124fa4da899b712a9a22af9f5",
            "440fd6a5834f44acbb32c362fce749a4",
            "0657445e0f3c409090bcb8cb9bb187a8",
            "a90fed65ed964ad48498acc661458fd8",
            "798a928097514c5fa8da79c9c266f858"
          ]
        },
        "id": "96128783",
        "outputId": "48f30c88-f023-47ac-9482-ddeae94db21c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.12/dist-packages (22.5)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: whisper-openai in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.12/dist-packages (15.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.1.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (10.8.0)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python==0.2.0->whisper-openai) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:00<00:00, 186MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e5e34f19d884885a3c38977b0705a7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a71987446a3d4206b49abcd98bb1874a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66deb0ce078446fda52ad66ebfceb3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e65ecd64c946c8a02c5fcce3efb5d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d2107f14ad64964890916f451af86f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f507492379143e0a41317cd89d806f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-zwnj-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "341bea3430fc4eeaa943118768d58d38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-4 (run_polling):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 105, in add_signal_handler\n",
            "    signal.set_wakeup_fd(self._csock.fileno())\n",
            "ValueError: set_wakeup_fd only works in main thread of the main interpreter\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\", line 839, in run_polling\n",
            "    return self.__run(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\", line 1044, in __run\n",
            "    loop.add_signal_handler(sig, self._raise_system_exit)\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 107, in add_signal_handler\n",
            "    raise RuntimeError(str(exc))\n",
            "RuntimeError: set_wakeup_fd only works in main thread of the main interpreter\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯! Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚ÙØŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ CTRL+C Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.12/threading.py:1077: RuntimeWarning: coroutine 'Updater.start_polling' was never awaited\n",
            "  self._invoke_excepthook(self)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Install necessary libraries and upgrade conflicting ones for dependency resolution\n",
        "!pip install --upgrade python-telegram-bot nest-asyncio whisper-openai pytube openai python-dotenv sentence-transformers transformers torch\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import sqlite3\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import whisper\n",
        "import tempfile\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "import asyncio\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "# import threading # Import threading - Removed threading as it conflicts with asyncio in this context\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops, necessary for running asyncio in environments like Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio for audio loading\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ùˆ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ â€” Ø§ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯\n",
        "BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\") # Corrected variable name\n",
        "SPONSOR_CHANNEL = os.environ.get(\"SPONSOR_CHANNEL\", \"@Radio_Zhelofen\") # Corrected variable name\n",
        "\n",
        "# --- Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ ---\n",
        "DB_NAME = 'users.db'\n",
        "\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        add_user(user_id) # Ensure user exists before returning default\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_user(user_id):\n",
        "     conn = None\n",
        "     try:\n",
        "         conn = sqlite3.connect(DB_NAME)\n",
        "         c = conn.cursor()\n",
        "         c.execute(\"INSERT OR IGNORE INTO users (user_id, usage_count, referral_count) VALUES (?, 0, 0)\", (user_id,))\n",
        "         conn.commit()\n",
        "         logger.info(f\"User {user_id} added to DB if not exists.\")\n",
        "     except sqlite3.Error as e:\n",
        "         logger.error(f\"Error adding user {user_id} to DB: {e}\")\n",
        "     finally:\n",
        "         if conn:\n",
        "             conn.close()\n",
        "\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET usage_count = usage_count + 1 WHERE user_id = ?\", (user_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ ---\n",
        "async def check_channel_membership(user_id, context: ContextTypes.DEFAULT_TYPE):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Load the Whisper model once at the beginning\n",
        "whisper_model = None\n",
        "try:\n",
        "    # Consider loading a smaller model if memory is an issue, e.g., \"base.en\" or \"small\"\n",
        "    # Also consider specifying device=\"cuda\" if a GPU is available and you have torch with CUDA\n",
        "    whisper_model = whisper.load_model(\"large\", device=\"cpu\") # Changed model to \"large\" and device to \"cpu\"\n",
        "    logger.info(\"Whisper model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading Whisper model: {e}\")\n",
        "\n",
        "\n",
        "# Load a text analysis model using Hugging Face pipeline\n",
        "text_analyzer = None\n",
        "try:\n",
        "    # Using a general-purpose text classification model for Persian as a placeholder.\n",
        "    # Finding a specific legal text analysis model for Persian in open-source is difficult.\n",
        "    # This model is a general Persian text classification model. Its suitability for legal analysis is limited.\n",
        "    # Replace with a more suitable model if one is found.\n",
        "    # Using a valid Persian text classification model from Hugging Face\n",
        "    model_name = \"HooshvareLab/bert-fa-zwnj-base\" # Corrected model name - using a general purpose Persian BERT model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    # The pipeline task might need adjustment depending on the specific model's intended use (e.g., sentiment-analysis, sequence-classification)\n",
        "    # For a general BERT model, 'feature-extraction' or 'fill-mask' might be more appropriate if not fine-tuned for a specific task.\n",
        "    # Assuming a classification task for now, but this might need refinement based on the desired legal analysis.\n",
        "    text_analyzer = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "    logger.info(\"Text analysis model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading text analysis model: {e}\")\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ø¯Ø³ØªÙˆØ± /start â€” Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ùˆ\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    add_user(user_id) # Ensure user exists for quota checks\n",
        "\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "        await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # If user is a member, show the main menu\n",
        "    keyboard = [\n",
        "        [\"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\", \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\"],\n",
        "        [\"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\", \"â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"ğŸ”° Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\\n\\n\"\n",
        "        \"Ù„Ø·ÙØ§Ù‹ ÛŒÚ©ÛŒ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "    # Then check usage quota\n",
        "    user_data = get_user_data(user_id)\n",
        "    FREE_USAGE_LIMIT = 5\n",
        "    REFERRAL_REQUIRED = 5\n",
        "\n",
        "    if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "        await update.message.reply_text(\n",
        "            f\"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† {FREE_USAGE_LIMIT} ØªØ§ÛŒÛŒ Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\"\n",
        "            f\"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "            \"Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø®ÙˆØ¯ØŒ Ø¨Ø§ Ù…Ø¯ÛŒØ± ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\" # Simplified message as referral link generation is not fully implemented\n",
        "        )\n",
        "        return\n",
        "\n",
        "    if whisper_model is None:\n",
        "        await update.message.reply_text(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ù…Ø¯ÛŒØ± Ø±Ø¨Ø§Øª Ø§Ø·Ù„Ø§Ø¹ Ø¯Ù‡ÛŒØ¯.\")\n",
        "        return\n",
        "\n",
        "    await update.message.reply_text(\"âœ… Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...\")\n",
        "\n",
        "    audio_path = None # Initialize audio_path to None\n",
        "    try:\n",
        "        voice_file = await update.message.voice.get_file()\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as tmp_file:\n",
        "            audio_path = tmp_file.name\n",
        "\n",
        "        await voice_file.download_to_drive(audio_path)\n",
        "\n",
        "        # Added error handling around transcription\n",
        "        try:\n",
        "            # Consider adding options like fp16=False if not using GPU or seeing issues\n",
        "            result = whisper_model.transcribe(audio_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†\")\n",
        "        except Exception as transcribe_error:\n",
        "            logger.error(f\"Error during Whisper transcription: {transcribe_error}\")\n",
        "            transcribed_text = \"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø¨Ù‡ Ù…ØªÙ† Ø±Ø® Ø¯Ø§Ø¯.\"\n",
        "\n",
        "\n",
        "        increment_usage(user_id)\n",
        "        user_data = get_user_data(user_id)\n",
        "        remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "        response_text = f\"ğŸ“ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:\\n\\n{transcribed_text}\\n\\n\"\n",
        "        if remaining_uses > 0:\n",
        "             response_text += f\"ğŸ”¢ Ø´Ù…Ø§ {remaining_uses} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒÚ¯Ø± Ø¯Ø§Ø±ÛŒØ¯.\"\n",
        "        else:\n",
        "             response_text += f\"ğŸ’¡ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ù„Ø·ÙØ§ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "        await update.message.reply_text(response_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling voice message: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "    finally:\n",
        "        # Ensure the temporary file is deleted\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                os.unlink(audio_path)\n",
        "                logger.info(f\"Temporary file deleted: {audio_path}\")\n",
        "            except Exception as cleanup_error:\n",
        "                logger.error(f\"Error deleting temporary file {audio_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    user_text = update.message.text\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "\n",
        "    if user_text == \"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\":\n",
        "        await update.message.reply_text(\"Ø§ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\")\n",
        "    elif user_text == \"â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§\":\n",
        "         await update.message.reply_text(\n",
        "             \"ğŸ“š **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§Øª:**\\n\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†ØŒ Ú¯Ø²ÛŒÙ†Ù‡ 'ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ú¯Ø²ÛŒÙ†Ù‡ 'ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "             \"â€¢ Ù‚Ø§Ø¨Ù„ÛŒØª 'ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯' Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒØŒ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "         )\n",
        "    elif text_analyzer is None:\n",
        "        await update.message.reply_text(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ù…Ø¯ÛŒØ± Ø±Ø¨Ø§Øª Ø§Ø·Ù„Ø§Ø¹ Ø¯Ù‡ÛŒØ¯.\")\n",
        "    else:\n",
        "        # Apply usage quota check for text analysis\n",
        "        user_data = get_user_data(user_id)\n",
        "        FREE_USAGE_LIMIT = 5\n",
        "        REFERRAL_REQUIRED = 5\n",
        "\n",
        "        if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "            await update.message.reply_text(\n",
        "                f\"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† {FREE_USAGE_LIMIT} ØªØ§ÛŒÛŒ Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\"\n",
        "                f\"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "                \"Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø®ÙˆØ¯ØŒ Ø¨Ø§ Ù…Ø¯ÛŒØ± ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "\n",
        "        await update.message.reply_text(\"âœ… Ù…ØªÙ† Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ...\")\n",
        "        formatted_result = \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\" # Initialize formatted_result\n",
        "        try:\n",
        "            # Added error handling around text analysis\n",
        "            try:\n",
        "                analysis_result = text_analyzer(user_text)\n",
        "                if analysis_result and isinstance(analysis_result, list) and len(analysis_result) > 0:\n",
        "                     formatted_result = f\"ğŸ“Š Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„:\\n\\n\"\n",
        "                     # The output format depends on the specific model.\n",
        "                     # For a classification model, it might be a list of labels and scores.\n",
        "                     # Adjust this formatting based on the actual output of the chosen Persian model.\n",
        "                     # Example formatting assuming a list of dicts with 'label' and 'score':\n",
        "                     for item in analysis_result:\n",
        "                          # Need to handle potential list of lists or other structures depending on the model\n",
        "                          if isinstance(item, list):\n",
        "                              for sub_item in item:\n",
        "                                   formatted_result += f\"- {sub_item.get('label', 'N/A')}: {sub_item.get('score', 0):.2f}\\n\"\n",
        "                          elif isinstance(item, dict):\n",
        "                               formatted_result += f\"- {item.get('label', 'N/A')}: {item.get('score', 0):.2f}\\n\"\n",
        "                          else:\n",
        "                               formatted_result += f\"- {item}\\n\" # Fallback for other output types\n",
        "\n",
        "\n",
        "                else:\n",
        "                     formatted_result = \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\"\n",
        "            except Exception as analysis_model_error:\n",
        "                 logger.error(f\"Error during text analysis model processing: {analysis_model_error}\")\n",
        "                 formatted_result = \"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø±Ø® Ø¯Ø§Ø¯.\"\n",
        "\n",
        "\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id)\n",
        "            remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "            response_text = f\"{formatted_result}\\n\\n\"\n",
        "            if remaining_uses > 0:\n",
        "                 response_text += f\"ğŸ”¢ Ø´Ù…Ø§ {remaining_uses} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒÚ¯Ø± Ø¯Ø§Ø±ÛŒØ¯.\"\n",
        "            else:\n",
        "                 response_text += f\"ğŸ’¡ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ù„Ø·ÙØ§ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"General error handling text message for analysis: {e}\")\n",
        "            # Avoid sending a generic error if a more specific one was already generated\n",
        "            if \"Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø±Ø® Ø¯Ø§Ø¯\" not in formatted_result and \\\n",
        "               \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯\" not in formatted_result:\n",
        "                 await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª\"\"\"\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE & ~filters.COMMAND, handle_voice)) # Ensure it only handles voice messages that are not commands\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)) # Ensure it only handles text messages that are not commands\n",
        "\n",
        "    print(\"âœ… Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§Ø³Øª...\")\n",
        "    # Added error handling for polling\n",
        "    try:\n",
        "        # Use asyncio.run to manage the event loop explicitly\n",
        "        asyncio.run(application.run_polling())\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"âŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ø®Ø·Ø§ Ù…ØªÙˆÙ‚Ù Ø´Ø¯: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934f28aa"
      },
      "source": [
        "## Ø§Ù†Ø¬Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø§Ù…Ø¹\n",
        "\n",
        "### Subtask:\n",
        "Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±Ø¨Ø§Øª Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ ØªØ³Øª Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ø´Ø§Ù…Ù„ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒØŒ Ø§Ø±Ø³Ø§Ù„ Ù…ØªÙˆÙ† Ù…Ø®ØªÙ„Ù (Ø­Ù‚ÙˆÙ‚ÛŒ Ùˆ ØºÛŒØ±Ø­Ù‚ÙˆÙ‚ÛŒ)ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø±Ø¨Ø§Øª Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ù†ÙˆØŒ Ùˆ ØªØ³Øª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª. Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø±Ø§ Ø«Ø¨Øª Ùˆ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù…Ø´Ú©Ù„ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HALl_daGMOj"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ## ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ· Ùˆ Ú©Ù„ÛŒØ¯Ù‡Ø§\n",
        "# Ù„Ø·ÙØ§Ù‹ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± ÙˆØ§Ù‚Ø¹ÛŒ Ø®ÙˆØ¯ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯.\n",
        "\n",
        "# %%\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ… ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø´Ù…Ø§\n",
        "os.environ['TELEGRAM_BOT_TOKEN'] = '7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc'  # ØªÙˆÚ©Ù† Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ… Ú©Ù„ÛŒØ¯ OpenAI Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ù…Ù„Ú©Ø±Ø¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ù…Ø§ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)\n",
        "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'  # Ø§Ú¯Ø± Ø¯Ø§Ø±ÛŒØ¯ØŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯\n",
        "\n",
        "# Ø¢Ø¯Ø±Ø³ Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± (Ø¨Ø§Øª Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø¯Ù…ÛŒÙ† Ø¨Ø§Ø´Ø¯)\n",
        "os.environ['SPONSOR_CHANNEL'] = '@Radio_Zhelofen'\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„\n",
        "model_size = \"large\"  # Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ØªØ± Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAT61mAaN0xm"
      },
      "outputs": [],
      "source": [
        "# Redundant installation cell, removing as dependencies are handled in the first cell\n",
        "# pip install transformers==4.37.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOsluWp2OWbA"
      },
      "outputs": [],
      "source": [
        "pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9NB4OlJOfO2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "print(pipeline('sentiment-analysis')('I love this!'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww3tJuKBRwkm"
      },
      "outputs": [],
      "source": [
        "# Redundant installation cell, removing as dependencies are handled in the first cell\n",
        "# pip install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# Ø­Ø§Ù„Ø§ Ú©Ø¯ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHGwyym0ML0d"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import logging\n",
        "import os\n",
        "import sqlite3\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import (\n",
        "    Application, CommandHandler, MessageHandler, filters,\n",
        "    ConversationHandler, CallbackContext, CallbackQueryHandler\n",
        ")\n",
        "import whisper\n",
        "import torch\n",
        "from pytube import YouTube\n",
        "import tempfile\n",
        "import re\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø¨Ø§Øª\n",
        "BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN', '7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc')\n",
        "SPONSOR_CHANNEL = os.getenv('SPONSOR_CHANNEL', '@Radio_Zhelofen')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'your-openai-api-key-here')\n",
        "\n",
        "# Ø­Ø§Ù„Øª Ù‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡\n",
        "CHOOSING, TRACKING_REFERRALS = range(2)\n",
        "\n",
        "# --- Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ùˆ Ø¯Ø¹ÙˆØªâ€ŒÙ‡Ø§ ---\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referred_by INTEGER,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute('''INSERT OR REPLACE INTO users\n",
        "                     (user_id, usage_count, referral_count)\n",
        "                     VALUES (?, COALESCE((SELECT usage_count FROM users WHERE user_id=?), 0) + 1,\n",
        "                             COALESCE((SELECT referral_count FROM users WHERE user_id=?), 0))''',\n",
        "                  (user_id, user_id, user_id))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ ---\n",
        "async def check_channel_membership(user_id, context: CallbackContext):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Ù…Ø¯ÛŒØ±ÛŒØª ÙˆÛŒØ¯ÛŒÙˆ Ùˆ ØµÙˆØª ---\n",
        "async def handle_media(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    try:\n",
        "        # Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª\n",
        "        if not await check_channel_membership(user_id, context):\n",
        "            await update.message.reply_text(\n",
        "                f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n{SPONSOR_CHANNEL}\\n\"\n",
        "                \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯ Ø§Ù‚Ø¯Ø§Ù… Ú©Ù†ÛŒØ¯.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        user_data = get_user_data(user_id)\n",
        "        if user_data['usage_count'] >= 5 and user_data['referral_count'] < 5:\n",
        "            await update.message.reply_text(\n",
        "                \"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\"\n",
        "                \"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ 5 Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "                \"Ø§Ø² Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Ú¯Ø²ÛŒÙ†Ù‡ 'Ø¯Ø¹ÙˆØª Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù†' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø³Ø§Ù†Ù‡\n",
        "        await update.message.reply_text(\"ğŸ¥ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ÛŒ...\")\n",
        "\n",
        "        if update.message.video:\n",
        "            file = await update.message.video.get_file()\n",
        "            suffix = '.mp4' # Assuming mp4 for video, adjust if needed\n",
        "        elif update.message.voice:\n",
        "            file = await update.message.voice.get_file()\n",
        "            suffix = '.ogg' # Assuming ogg for voice, adjust if needed\n",
        "        else:\n",
        "            await update.message.reply_text(\"âš ï¸ Ù„Ø·ÙØ§ ÛŒÚ© ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ ÛŒØ§ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "            return\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª\n",
        "        file_path = None # Initialize to None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:\n",
        "                file_path = tmp_file.name\n",
        "            await file.download_to_drive(file_path)\n",
        "\n",
        "            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†\n",
        "            model = whisper.load_model(\"base\") # Consider loading this once globally\n",
        "            result = model.transcribe(file_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†\")\n",
        "\n",
        "            # Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id) # Get updated data\n",
        "            remaining_uses = 5 - (user_data['usage_count']) # Assuming 5 is the limit\n",
        "\n",
        "\n",
        "            # Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡\n",
        "            response_text = (\n",
        "                f\"ğŸ“ **Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:**\\n\\n{transcribed_text}\\n\\n\"\n",
        "                f\"ğŸ”¢ Ø´Ù…Ø§ {max(0, 5 - user_data['usage_count'])} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒÚ¯Ø± Ø¯Ø§Ø±ÛŒØ¯.\" # Display remaining uses\n",
        "            )\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as processing_error:\n",
        "            logger.error(f\"Error during media processing: {processing_error}\")\n",
        "            await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "        finally:\n",
        "            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª\n",
        "            if file_path and os.path.exists(file_path):\n",
        "                try:\n",
        "                    os.unlink(file_path)\n",
        "                    logger.info(f\"Temporary file deleted: {file_path}\")\n",
        "                except Exception as cleanup_error:\n",
        "                    logger.error(f\"Error deleting temporary file {file_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"General error in handle_media: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "\n",
        "\n",
        "# --- Ø³ÛŒØ³ØªÙ… Ø¯Ø¹ÙˆØª Ø¯ÙˆØ³ØªØ§Ù† ---\n",
        "async def share_invite_link(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        bot_username = (await context.bot.get_me()).username\n",
        "        invite_link = f\"https://t.me/{bot_username}?start=ref{user_id}\"\n",
        "\n",
        "        await update.message.reply_text(\n",
        "            f\"ğŸ”— Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø§Ø®ØªØµØ§ØµÛŒ Ø´Ù…Ø§:\\n\\n`{invite_link}`\\n\\n\"\n",
        "            \"Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ³ØªØ§Ù† Ø®ÙˆØ¯ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯. Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØª Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ù†Ø§Ù†ØŒ \"\n",
        "            \"Ø³Ù‡Ù…ÛŒÙ‡ Ø´Ù…Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø®ÙˆØ§Ù‡Ø¯ ÛŒØ§ÙØª.\",\n",
        "            parse_mode='Markdown'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error sharing invite link: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "\n",
        "\n",
        "# --- Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø¹ÙˆØª Ø´Ø¯Ù‡ ---\n",
        "async def track_referral(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        args = context.args\n",
        "\n",
        "        if args and args[0].startswith('ref'):\n",
        "            try:\n",
        "                referrer_id = int(args[0][3:])\n",
        "                if referrer_id != user_id:\n",
        "                    add_referral(referrer_id)\n",
        "                    await update.message.reply_text(\n",
        "                        \"âœ… Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯! Ø´Ù…Ø§ Ø¨Ø§ Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª ÛŒÚ©ÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙˆØ§Ø±Ø¯ Ø´Ø¯ÛŒØ¯.\"\n",
        "                    )\n",
        "            except ValueError:\n",
        "                logger.error(f\"Invalid referrer ID format: {args[0]}\")\n",
        "                # Continue without adding referral if ID is invalid\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error tracking referral: {e}\")\n",
        "                # Continue without adding referral in case of other errors\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"General error in track_referral: {e}\")\n",
        "        # No message to user for this internal tracking function\n",
        "\n",
        "\n",
        "# --- Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ ---\n",
        "async def start(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        await track_referral(update, context) # Track referral on start\n",
        "\n",
        "        if not await check_channel_membership(user_id, context):\n",
        "            await update.message.reply_text(\n",
        "                f\"ğŸ”” Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\\n\\n\"\n",
        "                f\"Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\"\n",
        "                f\"{SPONSOR_CHANNEL}\\n\\n\"\n",
        "                f\"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "            )\n",
        "            return ConversationHandler.END\n",
        "\n",
        "        user_data = get_user_data(user_id)\n",
        "        keyboard = [\n",
        "            [InlineKeyboardButton(\"ğŸ¥ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ/ØµÙˆØª\", callback_data=\"upload_media\")],\n",
        "            [InlineKeyboardButton(\"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ\", callback_data=\"analyze_text\")],\n",
        "            [InlineKeyboardButton(\"ğŸ“„ ØªÙ†Ø¸ÛŒÙ… Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\", callback_data=\"generate_contract\")],\n",
        "            [InlineKeyboardButton(\"ğŸ”— Ø¯Ø¹ÙˆØª Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù†\", callback_data=\"invite_friends\")],\n",
        "            [InlineKeyboardButton(\"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø³Ù‡Ù…ÛŒÙ‡\", callback_data=\"usage_status\")]\n",
        "        ]\n",
        "        reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "        welcome_text = (\n",
        "            \"ğŸ‘‹ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\\n\\n\"\n",
        "            \"âš–ï¸ *Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø±Ø¨Ø§Øª:*\\n\"\n",
        "            \"â€¢ ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ùˆ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§\\n\"\n",
        "            \"â€¢ ØªØ­Ù„ÛŒÙ„ ØªØ®ØµØµÛŒ Ù…ØªÙˆÙ† Ø­Ù‚ÙˆÙ‚ÛŒ\\n\"\n",
        "            \"â€¢ ØªÙ†Ø¸ÛŒÙ… Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯\\n\"\n",
        "            \"â€¢ Ù¾Ø±Ø³Ø´ Ùˆ Ù¾Ø§Ø³Ø® Ø­Ù‚ÙˆÙ‚ÛŒ\\n\\n\"\n",
        "            \"Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ú¯Ø²ÛŒÙ†Ù‡ Ø±Ø§ Ø§Ø² Ù…Ù†ÙˆÛŒ Ø²ÛŒØ± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:\"\n",
        "        )\n",
        "        await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')\n",
        "        return CHOOSING\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in start handler: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "        return ConversationHandler.END # End conversation on error\n",
        "\n",
        "\n",
        "# --- Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†ØªØ®Ø§Ø¨ Ù‡Ø§ÛŒ Ù…Ù†Ùˆ ---\n",
        "async def handle_menu_selection(update: Update, context: CallbackContext):\n",
        "    query = update.callback_query\n",
        "    await query.answer()\n",
        "\n",
        "    user_id = query.from_user.id\n",
        "    user_data = get_user_data(user_id)\n",
        "\n",
        "    try:\n",
        "        if query.data == \"upload_media\":\n",
        "            if user_data['usage_count'] >= 5 and user_data['referral_count'] < 5:\n",
        "                await query.edit_message_text(\n",
        "                    \"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\\n\"\n",
        "                    \"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ûµ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø®ÙˆØ¯ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\\n\"\n",
        "                    \"Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡ 'Ø¯Ø¹ÙˆØª Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù†' Ø¯Ø± Ù…Ù†Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\"\n",
        "                )\n",
        "                return CHOOSING\n",
        "            else:\n",
        "                await query.edit_message_text(\n",
        "                    \"ğŸ¥ Ù„Ø·ÙØ§Ù‹ ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\\n\"\n",
        "                    \"âœ… Ø±Ø¨Ø§Øª Ø§Ø² ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\\n\"\n",
        "                    \"â±ï¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ù„Ø­Ø¸Ù‡ Ø²Ù…Ø§Ù† Ø¨Ø¨Ø±Ø¯.\"\n",
        "                )\n",
        "                return CHOOSING\n",
        "\n",
        "        elif query.data == \"invite_friends\":\n",
        "            bot_username = (await context.bot.get_me()).username\n",
        "            invite_link = f\"https://t.me/{bot_username}?start=ref{user_id}\"\n",
        "\n",
        "            await query.edit_message_text(\n",
        "                f\"ğŸ‘¥ **Ø³ÛŒØ³ØªÙ… Ø¯Ø¹ÙˆØª Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù†**\\n\\n\"\n",
        "                f\"ğŸ”— Ù„ÛŒÙ†Ú© Ø§Ø®ØªØµØ§ØµÛŒ Ø´Ù…Ø§:\\n`{invite_link}`\\n\\n\"\n",
        "                f\"ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ:\\n\"\n",
        "                f\"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒÙ‡Ø§: {user_data['usage_count']}/5\\n\"\n",
        "                f\"â€¢ Ø¯ÙˆØ³ØªØ§Ù† invited: {user_data['referral_count']}/5\\n\\n\"\n",
        "                f\"âœ… Ø¨Ø§ Ù‡Ø± Ûµ Ø¯Ø¹ÙˆØª Ù…ÙˆÙÙ‚ØŒ Ûµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            return CHOOSING\n",
        "\n",
        "        elif query.data == \"usage_status\":\n",
        "            await query.edit_message_text(\n",
        "                f\"ğŸ“Š **ÙˆØ¶Ø¹ÛŒØª Ø³Ù‡Ù…ÛŒÙ‡ Ø´Ù…Ø§**\\n\\n\"\n",
        "                f\"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒÙ‡Ø§: {user_data['usage_count']}/5\\n\"\n",
        "                f\"â€¢ Ø¯ÙˆØ³ØªØ§Ù† invited: {user_data['referral_count']}/5\\n\\n\"\n",
        "                f\"ğŸ” Ù¾Ø³ Ø§Ø² Ø§ØªÙ…Ø§Ù… Ø³Ù‡Ù…ÛŒÙ‡ØŒ Ø¨Ø§ Ø¯Ø¹ÙˆØª Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            return CHOOSING\n",
        "\n",
        "        else:\n",
        "            await query.edit_message_text(\"ğŸ› ï¸ Ø§ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\")\n",
        "            return CHOOSING\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in handle_menu_selection: {e}\")\n",
        "        await query.edit_message_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "        return CHOOSING # Stay in CHOOSING state\n",
        "\n",
        "\n",
        "# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---\n",
        "def main():\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    # Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡\n",
        "    conv_handler = ConversationHandler(\n",
        "        entry_points=[CommandHandler('start', start)],\n",
        "        states={\n",
        "            CHOOSING: [\n",
        "                CallbackQueryHandler(handle_menu_selection),\n",
        "                MessageHandler(filters.VIDEO | filters.VOICE, handle_media)\n",
        "            ]\n",
        "        },\n",
        "        fallbacks=[CommandHandler('start', start)]\n",
        "    )\n",
        "\n",
        "    application.add_handler(conv_handler)\n",
        "    # The following line is redundant because handle_media is already handled in the ConversationHandler\n",
        "    # application.add_handler(MessageHandler(filters.VIDEO | filters.VOICE, handle_media))\n",
        "\n",
        "    print(\"âœ… Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯! Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚ÙØŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ CTRL+C Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯.\")\n",
        "    try:\n",
        "        application.run_polling()\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"âŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ø®Ø·Ø§ Ù…ØªÙˆÙ‚Ù Ø´Ø¯: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaZvRmj0UQyn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3CNId8HUarK"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade python-telegram-bot whisper-openai transformers torch sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayzaH-tNYCip"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù„Ø§Ø²Ù… (Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯)\n",
        "# !pip install transformers torch torchaudio datasets\n",
        "\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio\n",
        "\n",
        "# ØªØ¹ÛŒÛŒÙ† Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø§Ø² GPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨Ø§Ø´Ø¯)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ùˆ Ù…Ø¯Ù„ large-v3\n",
        "model_name = \"openai/whisper-large-v3\"\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Ø§Ø®ØªÛŒØ§Ø±ÛŒ: Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø²Ø¨Ø§Ù†ØŒ Ø§ÛŒÙ† Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ Ø±Ø§ None Ø¨Ú¯Ø°Ø§Ø±\n",
        "model.config.forced_decoder_ids = None\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\n",
        "    \"\"\"\n",
        "    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ\n",
        "    # TODO: Load the audio file from audio_path using a library like torchaudio or librosa.\n",
        "    # Example with torchaudio:\n",
        "    # waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    # audio_sample = {\"array\": waveform.squeeze().numpy(), \"sampling_rate\": sample_rate}\n",
        "\n",
        "    # For now, using a placeholder for audio_sample\n",
        "    # Replace this with actual audio loading\n",
        "    audio_sample = None\n",
        "    print(f\"Placeholder: Loading audio from {audio_path}\") # Placeholder print statement\n",
        "\n",
        "    if audio_sample is None:\n",
        "        print(\"Error: Audio sample not loaded. Please implement audio loading.\")\n",
        "        return \"Error: Could not load audio.\"\n",
        "\n",
        "\n",
        "    # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ\n",
        "    input_features = processor(\n",
        "        audio_sample[\"array\"],\n",
        "        sampling_rate=audio_sample[\"sampling_rate\"],\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "\n",
        "    # ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆÚ©Ù†\n",
        "    predicted_ids = model.generate(input_features)\n",
        "\n",
        "    # Ø¯ÛŒÚ©Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ù…ØªÙ†\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "    return transcription[0]\n",
        "\n",
        "# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file_path = \"path/to/your/audio/file.wav\"  # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\n",
        "    # TODO: Replace the placeholder audio_file_path with the actual path to your audio file.\n",
        "    text_result = transcribe_audio(audio_file_path)\n",
        "    print(\"Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:\")\n",
        "    print(text_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "3a62a4b3",
        "outputId": "a5393f10-2360-4e10-931d-85c381cce2ce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'telegram'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2656183374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtelegram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtelegram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommandHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessageHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContextTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'telegram'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import logging\n",
        "import sqlite3\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import whisper\n",
        "import tempfile\n",
        "from transformers import pipeline\n",
        "import asyncio\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops, necessary for running asyncio in environments like Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio for audio loading\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ùˆ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ â€” Ø§ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯\n",
        "BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\") # Corrected variable name\n",
        "SPONSOR_CHANNEL = os.environ.get(\"SPONSOR_CHANNEL\", \"@Radio_Zhelofen\") # Corrected variable name\n",
        "\n",
        "# --- Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ ---\n",
        "DB_NAME = 'users.db'\n",
        "\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        add_user(user_id) # Ensure user exists before returning default\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_user(user_id):\n",
        "     conn = None\n",
        "     try:\n",
        "         conn = sqlite3.connect(DB_NAME)\n",
        "         c = conn.cursor()\n",
        "         c.execute(\"INSERT OR IGNORE INTO users (user_id, usage_count, referral_count) VALUES (?, 0, 0)\", (user_id,))\n",
        "         conn.commit()\n",
        "         logger.info(f\"User {user_id} added to DB if not exists.\")\n",
        "     except sqlite3.Error as e:\n",
        "         logger.error(f\"Error adding user {user_id} to DB: {e}\")\n",
        "     finally:\n",
        "         if conn:\n",
        "             conn.close()\n",
        "\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET usage_count = usage_count + 1 WHERE user_id = ?\", (user_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ ---\n",
        "async def check_channel_membership(user_id, context: ContextTypes.DEFAULT_TYPE):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Load the Whisper model once at the beginning\n",
        "whisper_model = None\n",
        "try:\n",
        "    # Consider loading a smaller model if memory is an issue, e.g., \"base.en\" or \"small\"\n",
        "    # Also consider specifying device=\"cuda\" if a GPU is available and you have torch with CUDA\n",
        "    whisper_model = whisper.load_model(\"base\")\n",
        "    logger.info(\"Whisper model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading Whisper model: {e}\")\n",
        "\n",
        "\n",
        "# Load a text analysis model using Hugging Face pipeline\n",
        "text_analyzer = None\n",
        "try:\n",
        "    # Using a general-purpose text classification model for Persian as a placeholder.\n",
        "    # Finding a specific legal text analysis model for Persian in open-source is difficult.\n",
        "    # This model is a general Persian text classification model. Its suitability for legal analysis is limited.\n",
        "    # Replace with a more suitable model if one is found.\n",
        "    text_analyzer = pipeline(\"text-classification\", model=\"persiannlp/ParsBert-Political-Text-Classification\") # Example Persian text classification model - replace if needed\n",
        "    logger.info(\"Text analysis model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading text analysis model: {e}\")\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ø¯Ø³ØªÙˆØ± /start â€” Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ùˆ\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    add_user(user_id) # Ensure user exists for quota checks\n",
        "\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "        await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # If user is a member, show the main menu\n",
        "    keyboard = [\n",
        "        [\"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\", \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\"],\n",
        "        [\"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\", \"â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"ğŸ”° Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\\n\\n\"\n",
        "        \"Ù„Ø·ÙØ§Ù‹ ÛŒÚ©ÛŒ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "    # Then check usage quota\n",
        "    user_data = get_user_data(user_id)\n",
        "    FREE_USAGE_LIMIT = 5\n",
        "    REFERRAL_REQUIRED = 5\n",
        "\n",
        "    if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "        await update.message.reply_text(\n",
        "            f\"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† {FREE_USAGE_LIMIT} ØªØ§ÛŒÛŒ Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\"\n",
        "            f\"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "            \"Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø®ÙˆØ¯ØŒ Ø¨Ø§ Ù…Ø¯ÛŒØ± ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\" # Simplified message as referral link generation is not fully implemented\n",
        "        )\n",
        "        return\n",
        "\n",
        "    if whisper_model is None:\n",
        "        await update.message.reply_text(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ù…Ø¯ÛŒØ± Ø±Ø¨Ø§Øª Ø§Ø·Ù„Ø§Ø¹ Ø¯Ù‡ÛŒØ¯.\")\n",
        "        return\n",
        "\n",
        "    await update.message.reply_text(\"âœ… Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...\")\n",
        "\n",
        "    audio_path = None # Initialize audio_path to None\n",
        "    try:\n",
        "        voice_file = await update.message.voice.get_file()\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as tmp_file:\n",
        "            audio_path = tmp_file.name\n",
        "\n",
        "        await voice_file.download_to_drive(audio_path)\n",
        "\n",
        "        # Added error handling around transcription\n",
        "        try:\n",
        "            # Consider adding options like fp16=False if not using GPU or seeing issues\n",
        "            result = whisper_model.transcribe(audio_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†\")\n",
        "        except Exception as transcribe_error:\n",
        "            logger.error(f\"Error during Whisper transcription: {transcribe_error}\")\n",
        "            transcribed_text = \"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø¨Ù‡ Ù…ØªÙ† Ø±Ø® Ø¯Ø§Ø¯.\"\n",
        "\n",
        "\n",
        "        increment_usage(user_id)\n",
        "        user_data = get_user_data(user_id)\n",
        "        remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "        response_text = f\"ğŸ“ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:\\n\\n{transcribed_text}\\n\\n\"\n",
        "        if remaining_uses > 0:\n",
        "             response_text += f\"ğŸ”¢ Ø´Ù…Ø§ {remaining_uses} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒÚ¯Ø± Ø¯Ø§Ø±ÛŒØ¯.\"\n",
        "        else:\n",
        "             response_text += f\"ğŸ’¡ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ù„Ø·ÙØ§ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "        await update.message.reply_text(response_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling voice message: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "    finally:\n",
        "        # Ensure the temporary file is deleted\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                os.unlink(audio_path)\n",
        "                logger.info(f\"Temporary file deleted: {audio_path}\")\n",
        "            except Exception as cleanup_error:\n",
        "                logger.error(f\"Error deleting temporary file {audio_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    user_text = update.message.text\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "            f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "\n",
        "    if user_text == \"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\":\n",
        "        await update.message.reply_text(\"Ø§ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\")\n",
        "    elif user_text == \"â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§\":\n",
        "         await update.message.reply_text(\n",
        "             \"ğŸ“š **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§Øª:**\\n\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†ØŒ Ú¯Ø²ÛŒÙ†Ù‡ 'ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒØŒ Ú¯Ø²ÛŒÙ†Ù‡ 'ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "             \"â€¢ Ù‚Ø§Ø¨Ù„ÛŒØª 'ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯' Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\\n\"\n",
        "             \"â€¢ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒØŒ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "         )\n",
        "    elif text_analyzer is None:\n",
        "        await update.message.reply_text(\"âŒ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø¯Ù„ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ù‡ Ù…Ø¯ÛŒØ± Ø±Ø¨Ø§Øª Ø§Ø·Ù„Ø§Ø¹ Ø¯Ù‡ÛŒØ¯.\")\n",
        "    else:\n",
        "        # Apply usage quota check for text analysis\n",
        "        user_data = get_user_data(user_id)\n",
        "        FREE_USAGE_LIMIT = 5\n",
        "        REFERRAL_REQUIRED = 5\n",
        "\n",
        "        if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "            await update.message.reply_text(\n",
        "                f\"âŒ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† {FREE_USAGE_LIMIT} ØªØ§ÛŒÛŒ Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.\\n\"\n",
        "                f\"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\\n\"\n",
        "                \"Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú© Ø¯Ø¹ÙˆØª Ø®ÙˆØ¯ØŒ Ø¨Ø§ Ù…Ø¯ÛŒØ± ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "\n",
        "        await update.message.reply_text(\"âœ… Ù…ØªÙ† Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ...\")\n",
        "        formatted_result = \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\" # Initialize formatted_result\n",
        "        try:\n",
        "            # Added error handling around text analysis\n",
        "            try:\n",
        "                analysis_result = text_analyzer(user_text)\n",
        "                if analysis_result and isinstance(analysis_result, list) and len(analysis_result) > 0:\n",
        "                     formatted_result = f\"ğŸ“Š Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„:\\n\\n\"\n",
        "                     # The output format depends on the specific model.\n",
        "                     # For a classification model, it might be a list of labels and scores.\n",
        "                     # Adjust this formatting based on the actual output of the chosen Persian model.\n",
        "                     # Example formatting assuming a list of dicts with 'label' and 'score':\n",
        "                     for item in analysis_result:\n",
        "                          # Need to handle potential list of lists or other structures depending on the model\n",
        "                          if isinstance(item, list):\n",
        "                              for sub_item in item:\n",
        "                                   formatted_result += f\"- {sub_item.get('label', 'N/A')}: {sub_item.get('score', 0):.2f}\\n\"\n",
        "                          elif isinstance(item, dict):\n",
        "                               formatted_result += f\"- {item.get('label', 'N/A')}: {item.get('score', 0):.2f}\\n\"\n",
        "                          else:\n",
        "                               formatted_result += f\"- {item}\\n\" # Fallback for other output types\n",
        "\n",
        "\n",
        "                else:\n",
        "                     formatted_result = \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.\"\n",
        "            except Exception as analysis_model_error:\n",
        "                 logger.error(f\"Error during text analysis model processing: {analysis_model_error}\")\n",
        "                 formatted_result = \"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø±Ø® Ø¯Ø§Ø¯.\"\n",
        "\n",
        "\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id)\n",
        "            remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "            response_text = f\"{formatted_result}\\n\\n\"\n",
        "            if remaining_uses > 0:\n",
        "                 response_text += f\"ğŸ”¢ Ø´Ù…Ø§ {remaining_uses} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒÚ¯Ø± Ø¯Ø§Ø±ÛŒØ¯.\"\n",
        "            else:\n",
        "                 response_text += f\"ğŸ’¡ Ø³Ù‡Ù…ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ØŒ Ù„Ø·ÙØ§ {REFERRAL_REQUIRED} Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.\"\n",
        "\n",
        "\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"General error handling text message for analysis: {e}\")\n",
        "            # Avoid sending a generic error if a more specific one was already generated\n",
        "            if \"Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø±Ø® Ø¯Ø§Ø¯\" not in formatted_result and \\\n",
        "               \"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯\" not in formatted_result:\n",
        "                 await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª\"\"\"\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE & ~filters.COMMAND, handle_voice)) # Ensure it only handles voice messages that are not commands\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)) # Ensure it only handles text messages that are not commands\n",
        "\n",
        "    print(\"âœ… Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯! Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚ÙØŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ CTRL+C Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯.\")\n",
        "    # Added error handling for polling\n",
        "    try:\n",
        "        application.run_polling()\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"âŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ø®Ø·Ø§ Ù…ØªÙˆÙ‚Ù Ø´Ø¯: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "nzciVNrhUE8A",
        "outputId": "4e25b97e-1da9-4b5e-e6f3-1f6420c1f2ae"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3582663576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ØªØºÛŒÛŒØ± Ø§Ø² Ù…Ø¯Ù„ base Ø¨Ù‡ large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GPU Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                         return _load(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                             \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                             \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2117\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_weights_only_unpickler.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m                         \u001b[0;34mf\"Only persistent_load of storage is allowed, but got {pid[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                     )\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONG_BINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   2084\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_fake_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fake_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \"\"\"\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "# ØªØºÛŒÛŒØ± Ø§Ø² Ù…Ø¯Ù„ base Ø¨Ù‡ large\n",
        "model = whisper.load_model(\"large\", device=\"cuda\")  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GPU Ø§Ú¯Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "mq3gyxg2MiKW",
        "outputId": "7d43f8d3-20c6-4cf9-f860-0fdb18bb4b06"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Cannot close a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_shutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3458777013.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3458777013.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36mrun_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         return self.__run(\n\u001b[0m\u001b[1;32m    840\u001b[0m             updater_coroutine=self.updater.start_polling(\n\u001b[1;32m    841\u001b[0m                 \u001b[0mpoll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclose_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     def create_task(\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import logging\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, MessageHandler, filters, ContextTypes\n",
        "\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ùˆ Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ â€” Ø§ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯\n",
        "BOT_TOKEN = os.environ.get(\"BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\")\n",
        "SPONSOR_CHANNEL = \"@Radio_Zhelofen\"  # Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø±\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ø¯Ø³ØªÙˆØ± /start â€” Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ùˆ\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø±\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        if member.status not in [\"member\", \"administrator\", \"creator\"]:\n",
        "            await update.message.reply_text(\n",
        "                f\"âš ï¸ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø§Ø³Ù¾Ø§Ù†Ø³Ø± Ù…Ø§ Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯:\\n\\n\"\n",
        "                f\"ğŸŒ {SPONSOR_CHANNEL}\\n\\n\"\n",
        "                \"Ù¾Ø³ Ø§Ø² Ø¹Ø¶ÙˆÛŒØªØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¯Ø³ØªÙˆØ± /start Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\"\n",
        "            )\n",
        "            return\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ú©Ø§Ù†Ø§Ù„: {e}\")\n",
        "        await update.message.reply_text(\"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.\")\n",
        "        return\n",
        "\n",
        "    # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¹Ø¶Ùˆ Ú©Ø§Ù†Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯\n",
        "    keyboard = [\n",
        "        [\"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\", \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\"],\n",
        "        [\"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\", \"â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"ğŸ”° Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\\n\\n\"\n",
        "        \"Ù„Ø·ÙØ§Ù‹ ÛŒÚ©ÛŒ Ø§Ø² Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†\"\"\"\n",
        "    # Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ÛŒØ¯ Ú©Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…Ø¯Ù„ Ù…ØªÙ†â€ŒØ¨Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† (Ù…Ø«Ù„Ø§Ù‹ Whisper) ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆØ¯.\n",
        "    await update.message.reply_text(\"âœ… Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...\")\n",
        "\n",
        "    # TODO: Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†â€ŒØ¨Ø§Ø² Ù…Ø§Ù†Ù†Ø¯ Whisper ØªÚ©Ù…ÛŒÙ„ Ø´ÙˆØ¯\n",
        "    # voice_file = await update.message.voice.get_file()\n",
        "    # transcribed_text = your_whisper_function(voice_file.file_path)\n",
        "\n",
        "    transcribed_text = \"Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø² ØµÙˆØª\"  # Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª\n",
        "\n",
        "    await update.message.reply_text(f\"ğŸ“ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:\\n\\n{transcribed_text}\")\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ\"\"\"\n",
        "    user_text = update.message.text\n",
        "\n",
        "    if user_text == \"ğŸ¤ ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“ ØªØ­Ù„ÛŒÙ„ Ø­Ù‚ÙˆÙ‚ÛŒ Ù…ØªÙ†\":\n",
        "        await update.message.reply_text(\"Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.\")\n",
        "    elif user_text == \"ğŸ“„ Ø³Ø§Ø®Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯\":\n",
        "        await update.message.reply_text(\"Ø§ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØª Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.\")\n",
        "    else:\n",
        "        # TODO: Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ Ù…ØªÙ†â€ŒØ¨Ø§Ø² (Ù…Ø«Ù„Ø§Ù‹ Ø§Ø² Hugging Face) Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† ØªÚ©Ù…ÛŒÙ„ Ø´ÙˆØ¯\n",
        "        await update.message.reply_text(\"Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. (ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ)\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª\"\"\"\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    # Ø«Ø¨Øª Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE, handle_voice))\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))\n",
        "\n",
        "    # Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª\n",
        "    application.run_polling()\n",
        "    print(\"Ø±Ø¨Ø§Øª ÙØ¹Ø§Ù„ Ø´Ø¯!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "oLlVgDx5Up0r",
        "outputId": "7e52ab46-1efa-41e1-9ffd-3d51eb1c02a1"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 2 (ipython-input-694587228.py, line 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-694587228.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 2\n"
          ]
        }
      ],
      "source": [
        "async def handle_media(update: Update, context: CallbackContext):\n",
        "    try:\n",
        "        # Ú©Ø¯ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø³Ø§Ù†Ù‡: {e}\")\n",
        "        await update.message.reply_text(\"âš ï¸ Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bed41458"
      },
      "source": [
        "# Task\n",
        "Debug the provided Python code for a Telegram bot, specifically addressing issues related to voice-to-text conversion errors, non-functional features, and general bugs. The debugging process should involve examining logs, completing incomplete code sections (voice-to-text and text analysis), reviewing message handling logic, checking membership/quota systems (if applicable), adding error handling, and performing comprehensive testing. The final response should be in Persian, explaining the root cause of the errors and why other features are not working."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5d9e60d"
      },
      "source": [
        "## Ø¨Ø±Ø±Ø³ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ùˆ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯\n",
        "\n",
        "### Subtask:\n",
        "Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒØŒ Ø¨Ù‡ Ø®ØµÙˆØµ `vHGwyym0ML0d` Ùˆ `mq3gyxg2MiKW` Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ ÛŒØ§ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2913622"
      },
      "source": [
        "## ØªÚ©Ù…ÛŒÙ„ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†\n",
        "\n",
        "### Subtask:\n",
        "Ú©Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Whisper (ÛŒØ§ Ù…Ø¯Ù„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†) Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ Ù…ØªÙ† Ø±Ø§ Ø¯Ø± ØªØ§Ø¨Ø¹ `handle_voice` Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4a5e13"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the voice-to-text conversion in the `handle_voice` function by loading the Whisper model, downloading the audio file, transcribing it, and sending the result to the user, ensuring temporary files are handled properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a8c1b01"
      },
      "source": [
        "## ØªÚ©Ù…ÛŒÙ„ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ\n",
        "\n",
        "### Subtask:\n",
        "Ú©Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ (Ù…Ø§Ù†Ù†Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face) Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø­Ù‚ÙˆÙ‚ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¯Ø± ØªØ§Ø¨Ø¹ `handle_text` Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e945eb05"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the text analysis feature using a Hugging Face model within the `handle_text` function. This involves loading a suitable model and tokenizer, processing the user's text, and sending the result back.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c0f4d33"
      },
      "source": [
        "## Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ù…Ù†Ø·Ù‚ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§\n",
        "\n",
        "### Subtask:\n",
        "Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ `MessageHandler` Ù‡Ø§ Ùˆ `CommandHandler` Ù‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù (Ø¯Ø³ØªÙˆØ± `start`ØŒ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒØŒ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ) Ø¨Ù‡ ØªÙˆØ§Ø¨Ø¹ ØµØ­ÛŒØ­ Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ù…Ù†Ø·Ù‚ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…Ù†Ùˆ Ùˆ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ú©Ù†ÛŒØ¯.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d1c9f5"
      },
      "source": [
        "**Reasoning**:\n",
        "Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ú©Ù‡ Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªØ¹Ø±ÛŒÙ Ùˆ Ø¨Ù‡ application Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…Ù†Ø·Ù‚ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø¯Ø± ØªØ§Ø¨Ø¹ `handle_text` ØµØ­ÛŒØ­ Ø§Ø³Øª.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "375d0647"
      },
      "source": [
        "## Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø·Ù‚ Ø³ÛŒØ³ØªÙ… Ø¹Ø¶ÙˆÛŒØª Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ø³ØªÙØ§Ø¯Ù‡)\n",
        "\n",
        "### Subtask:\n",
        "Ø§Ú¯Ø± Ø§Ø² Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ ÛŒØ§ Ø³Ù‡Ù…ÛŒÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ (Ù…Ø§Ù†Ù†Ø¯ Ø¢Ù†Ú†Ù‡ Ø¯Ø± Ø³Ù„ÙˆÙ„ `vHGwyym0ML0d` Ø¨ÙˆØ¯)ØŒ Ù…Ù†Ø·Ù‚ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¯Ø± Ù…Ú©Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù…Ø«Ù„Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ø®Ø¯Ù…Ø§Øª Ø§ØµÙ„ÛŒ) Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dce2ca8"
      },
      "source": [
        "**Reasoning**:\n",
        "Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ú©Ù‡ Ø¢ÛŒØ§ Ù…Ù†Ø·Ù‚ Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ø³ÛŒØ³ØªÙ… Ø³Ù‡Ù…ÛŒÙ‡ Ø¯Ø± Ú©Ø¯ ÙØ¹Ù„ÛŒ (Ø³Ù„ÙˆÙ„ `mq3gyxg2MiKW`) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®ÛŒØ±. Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù… Ú©Ù‡ Ø¢ÛŒØ§ Ø¢Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†Ù… ÛŒØ§ Ø®ÛŒØ± Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ… Ù…Ù†Ø·Ù‚ Ø¢Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ù….\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02c318e3"
      },
      "source": [
        "**Reasoning**:\n",
        "Ù…Ù†Ø·Ù‚ Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ø¶ÙˆÛŒØª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ùˆ Ø³ÛŒØ³ØªÙ… Ø³Ù‡Ù…ÛŒÙ‡ Ø¨Ù‡ Ú©Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø­Ø§Ù„Ø§ Ø¨Ø§ÛŒØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†Ù… Ú©Ù‡ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ù…Ú©Ø§Ù†â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­ (ÛŒØ¹Ù†ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ø®Ø¯Ù…Ø§Øª Ø§ØµÙ„ÛŒ) Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fc9d57e"
      },
      "outputs": [],
      "source": [
        "# Run the bot code cell\n",
        "# Removed get_ipython().run_cell('96128783') to avoid running main multiple times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94672b4a",
        "outputId": "30200c57-4e98-4570-fba2-7e832736cccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.12/dist-packages (22.5)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e01f82"
      },
      "source": [
        "## Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§\n",
        "\n",
        "### Subtask:\n",
        "Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø² Ú©Ø§Ø± Ø§ÙØªØ§Ø¯Ù† Ø±Ø¨Ø§Øª Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ù…Ø´Ú©Ù„Ø§Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ø·ÙˆÙ„ Ø§Ø¬Ø±Ø§ÛŒ ØªÙˆØ§Ø¨Ø¹ Ù…Ø®ØªÙ„Ù.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2e2ec8"
      },
      "source": [
        "**Reasoning**:\n",
        "Add try...except blocks to the relevant functions and model loading sections to handle potential errors, log them, and send user-friendly messages, fulfilling the error handling requirement of the subtask.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNswmVDRSg1YuvLnjtmamfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e5e34f19d884885a3c38977b0705a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f1241acb0234a6486bc36922fcc90a8",
              "IPY_MODEL_ca4a185f8c4943979be80ec31613dce9",
              "IPY_MODEL_9eb60c187a3045c4a88734258fb01f04"
            ],
            "layout": "IPY_MODEL_c936a30f62e34fb1b8977f2f0cb4660d"
          }
        },
        "1f1241acb0234a6486bc36922fcc90a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7af069d3fded4f7986b556b85aa4afb5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2219741944524fc583db7558a6efbc42",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "ca4a185f8c4943979be80ec31613dce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2775aeb495f4176b4684f460256a518",
            "max": 292,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_990218703b0b4ffbb07d148eca82d998",
            "value": 292
          }
        },
        "9eb60c187a3045c4a88734258fb01f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3959ace5492242d6b29a3bf91ac7aa99",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_833e410d4f7d4cc4982c242676e75baf",
            "value": "â€‡292/292â€‡[00:00&lt;00:00,â€‡24.2kB/s]"
          }
        },
        "c936a30f62e34fb1b8977f2f0cb4660d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af069d3fded4f7986b556b85aa4afb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2219741944524fc583db7558a6efbc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2775aeb495f4176b4684f460256a518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990218703b0b4ffbb07d148eca82d998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3959ace5492242d6b29a3bf91ac7aa99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833e410d4f7d4cc4982c242676e75baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71987446a3d4206b49abcd98bb1874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95113e7ba22a442590a51dbcb009b6e2",
              "IPY_MODEL_87ef098897564d628ce320e649d70e28",
              "IPY_MODEL_d012be5b6b51473991fb258f41b1a264"
            ],
            "layout": "IPY_MODEL_f859d1b98b124b06b298b3564a05d719"
          }
        },
        "95113e7ba22a442590a51dbcb009b6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_993f420e78814ef399ae11ccd44e201e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_611d9bb671934f7795a2c52042265f35",
            "value": "config.json:â€‡100%"
          }
        },
        "87ef098897564d628ce320e649d70e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b55b5d4d87ac4e29bea6ca58749a4f12",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8acba16a03b4f9db6df413afa3614bb",
            "value": 565
          }
        },
        "d012be5b6b51473991fb258f41b1a264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a340bfe506e0413eba2478d11d652543",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_792cce6a91cb4fbdb39a829168b8d77a",
            "value": "â€‡565/565â€‡[00:00&lt;00:00,â€‡47.7kB/s]"
          }
        },
        "f859d1b98b124b06b298b3564a05d719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993f420e78814ef399ae11ccd44e201e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611d9bb671934f7795a2c52042265f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55b5d4d87ac4e29bea6ca58749a4f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8acba16a03b4f9db6df413afa3614bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a340bfe506e0413eba2478d11d652543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792cce6a91cb4fbdb39a829168b8d77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66deb0ce078446fda52ad66ebfceb3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_993db2903cab423dbecb32a3dd4cb26c",
              "IPY_MODEL_614d1d10c5fd46b5ba467603dc52026e",
              "IPY_MODEL_293d45e33f7143548eccb114c799caa9"
            ],
            "layout": "IPY_MODEL_0f00bb9e0d2d43cfb22f9fd4238b7092"
          }
        },
        "993db2903cab423dbecb32a3dd4cb26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26f0a13cb5345dabe14aa299bef296b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_43d440a6d0aa410d8d910238291aa1e8",
            "value": "vocab.txt:â€‡"
          }
        },
        "614d1d10c5fd46b5ba467603dc52026e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f0dd17eb134f6d82ac13a948739dcb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1deb5b37670b40bcb050c19b913af3c2",
            "value": 1
          }
        },
        "293d45e33f7143548eccb114c799caa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0572e86c8da3443fa4b37e835bef21a4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3cdd65b8b4944583b6b1dedf2f120eb2",
            "value": "â€‡426k/?â€‡[00:00&lt;00:00,â€‡11.2MB/s]"
          }
        },
        "0f00bb9e0d2d43cfb22f9fd4238b7092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26f0a13cb5345dabe14aa299bef296b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d440a6d0aa410d8d910238291aa1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f0dd17eb134f6d82ac13a948739dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1deb5b37670b40bcb050c19b913af3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0572e86c8da3443fa4b37e835bef21a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cdd65b8b4944583b6b1dedf2f120eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e65ecd64c946c8a02c5fcce3efb5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79ba7084f0084958b0f2921379856899",
              "IPY_MODEL_6db966099fdf4364930a3a9283a20f2a",
              "IPY_MODEL_0853b2621cc44531a88d7e00417d812b"
            ],
            "layout": "IPY_MODEL_0c98c5414519401a8b662f06d2757e73"
          }
        },
        "79ba7084f0084958b0f2921379856899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b44407dc1234070874ff86dc8965f01",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_48e7d484489f4dcd97603fe2c4b0e9e8",
            "value": "tokenizer.json:â€‡"
          }
        },
        "6db966099fdf4364930a3a9283a20f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6eaf8fa2ad479da8d8be9bbac1237f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d67c3df01e4e4d92983f06c26560cde8",
            "value": 1
          }
        },
        "0853b2621cc44531a88d7e00417d812b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d0e946289a490fadd14a73d9735604",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b821ec5af006453a835f93c1bcd65292",
            "value": "â€‡1.11M/?â€‡[00:00&lt;00:00,â€‡34.3MB/s]"
          }
        },
        "0c98c5414519401a8b662f06d2757e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b44407dc1234070874ff86dc8965f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e7d484489f4dcd97603fe2c4b0e9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6eaf8fa2ad479da8d8be9bbac1237f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d67c3df01e4e4d92983f06c26560cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63d0e946289a490fadd14a73d9735604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b821ec5af006453a835f93c1bcd65292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2107f14ad64964890916f451af86f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d45f125223504cb39b07621cfd325fd4",
              "IPY_MODEL_b3cda01c19144229bb4bc0536ab7c578",
              "IPY_MODEL_06eb5668fc574a0dac13f8bbdb06680f"
            ],
            "layout": "IPY_MODEL_e5691d659a5049d996de42216f33ece7"
          }
        },
        "d45f125223504cb39b07621cfd325fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5eb436a23ab40d0951a8d947634e7d1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9233c7b599824142a8d2cf1810c868a7",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "b3cda01c19144229bb4bc0536ab7c578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e044571c13e445409c0ae56031ba164c",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ab45e72c5843f88c8ab7b1224600dd",
            "value": 134
          }
        },
        "06eb5668fc574a0dac13f8bbdb06680f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262644632c0d453f9094271f0df88dc5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_af3b1ab6a34c436dab24382a91bfc5cc",
            "value": "â€‡134/134â€‡[00:00&lt;00:00,â€‡12.7kB/s]"
          }
        },
        "e5691d659a5049d996de42216f33ece7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5eb436a23ab40d0951a8d947634e7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9233c7b599824142a8d2cf1810c868a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e044571c13e445409c0ae56031ba164c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ab45e72c5843f88c8ab7b1224600dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "262644632c0d453f9094271f0df88dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3b1ab6a34c436dab24382a91bfc5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f507492379143e0a41317cd89d806f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a67bb6314f60489f9075e4cac75ff273",
              "IPY_MODEL_3d651afbb91845ea9ac17b5fe3276d6a",
              "IPY_MODEL_a4fa9c8a6038400086b1adfdd6bd2a55"
            ],
            "layout": "IPY_MODEL_dc72e05be2854a19b4868432eb058e24"
          }
        },
        "a67bb6314f60489f9075e4cac75ff273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffcd85dd0e94651aab6a15bafe3ee32",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f13ef86f6bf446e909e5cf122d76bf5",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "3d651afbb91845ea9ac17b5fe3276d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf136179ed324817b3af35cd2c8cfb5e",
            "max": 473451616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69103b7075e54b6a8175c4ceb8c5e903",
            "value": 473451616
          }
        },
        "a4fa9c8a6038400086b1adfdd6bd2a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc504f7824f346c398c69663e811872d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_413708a77b024c57bae6c229a59a372c",
            "value": "â€‡473M/473Mâ€‡[00:06&lt;00:00,â€‡77.9MB/s]"
          }
        },
        "dc72e05be2854a19b4868432eb058e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffcd85dd0e94651aab6a15bafe3ee32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f13ef86f6bf446e909e5cf122d76bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf136179ed324817b3af35cd2c8cfb5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69103b7075e54b6a8175c4ceb8c5e903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc504f7824f346c398c69663e811872d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413708a77b024c57bae6c229a59a372c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341bea3430fc4eeaa943118768d58d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6a64b9a1274d6a803d8e57075a7d8e",
              "IPY_MODEL_44763f4b1745400ba706f9afcb9a2338",
              "IPY_MODEL_f9815cbf367d4f27bf0f7a8baa0a268f"
            ],
            "layout": "IPY_MODEL_a1512da8a42e40c9be4aef79967d7c27"
          }
        },
        "3a6a64b9a1274d6a803d8e57075a7d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e957510f5b4215ac60da1c8b94e0c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd3c992124fa4da899b712a9a22af9f5",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "44763f4b1745400ba706f9afcb9a2338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440fd6a5834f44acbb32c362fce749a4",
            "max": 473391424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0657445e0f3c409090bcb8cb9bb187a8",
            "value": 473391424
          }
        },
        "f9815cbf367d4f27bf0f7a8baa0a268f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90fed65ed964ad48498acc661458fd8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_798a928097514c5fa8da79c9c266f858",
            "value": "â€‡473M/473Mâ€‡[00:04&lt;00:00,â€‡135MB/s]"
          }
        },
        "a1512da8a42e40c9be4aef79967d7c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e957510f5b4215ac60da1c8b94e0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3c992124fa4da899b712a9a22af9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440fd6a5834f44acbb32c362fce749a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0657445e0f3c409090bcb8cb9bb187a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a90fed65ed964ad48498acc661458fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798a928097514c5fa8da79c9c266f858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}