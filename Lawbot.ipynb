{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaghaghi20/legal-asist-bot/blob/main/Lawbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tufg7EvF7qV5",
        "outputId": "f8f7d09d-05a1-4e6e-e1ca-c93e0059fbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-22.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting whisper-openai\n",
            "  Downloading whisper_openai-1.0.0-py3-none-any.whl.metadata (480 bytes)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.1.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (10.8.0)\n",
            "Collecting ffmpeg-python==0.2.0 (from whisper-openai)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python==0.2.0->whisper-openai) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Downloading python_telegram_bot-22.5-py3-none-any.whl (730 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.0/731.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading whisper_openai-1.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.1.0-py3-none-any.whl (964 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m964.9/964.9 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, ffmpeg-python, python-telegram-bot, openai, transformers, whisper-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-2.1.0 python-telegram-bot-22.5 pytube-15.0.0 transformers-4.57.0 whisper-openai-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## نصب پیش‌نیازها\n",
        "# اجرای این سلول ممکن است چند دقیقه زمان ببرد.\n",
        "\n",
        "# %%\n",
        "# Install necessary libraries including nest-asyncio and upgrade conflicting ones for dependency resolution\n",
        "!pip install --upgrade python-telegram-bot nest-asyncio whisper-openai pytube openai python-dotenv sentence-transformers transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ff689d5"
      },
      "outputs": [],
      "source": [
        "# Removed redundant cell execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "530b8678"
      },
      "source": [
        "## انجام تست‌های جامع\n",
        "\n",
        "### Subtask:\n",
        "ربات هم‌اکنون فعال است. عملکرد آن را به طور کامل تست کنید. این شامل ارسال پیام‌های صوتی برای تست قابلیت تبدیل صوت به متن، ارسال متون مختلف (حقوقی و غیرحقوقی) برای تست قابلیت تحلیل متن، بررسی پاسخ ربات به انتخاب‌های منو، و تست سناریوهای مربوط به عضویت در کانال و سهمیه استفاده است. نتایج تست را ثبت و هرگونه مشکل باقی‌مانده را شناسایی کنید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1e5e34f19d884885a3c38977b0705a7a",
            "1f1241acb0234a6486bc36922fcc90a8",
            "ca4a185f8c4943979be80ec31613dce9",
            "9eb60c187a3045c4a88734258fb01f04",
            "c936a30f62e34fb1b8977f2f0cb4660d",
            "7af069d3fded4f7986b556b85aa4afb5",
            "2219741944524fc583db7558a6efbc42",
            "e2775aeb495f4176b4684f460256a518",
            "990218703b0b4ffbb07d148eca82d998",
            "3959ace5492242d6b29a3bf91ac7aa99",
            "833e410d4f7d4cc4982c242676e75baf",
            "a71987446a3d4206b49abcd98bb1874a",
            "95113e7ba22a442590a51dbcb009b6e2",
            "87ef098897564d628ce320e649d70e28",
            "d012be5b6b51473991fb258f41b1a264",
            "f859d1b98b124b06b298b3564a05d719",
            "993f420e78814ef399ae11ccd44e201e",
            "611d9bb671934f7795a2c52042265f35",
            "b55b5d4d87ac4e29bea6ca58749a4f12",
            "b8acba16a03b4f9db6df413afa3614bb",
            "a340bfe506e0413eba2478d11d652543",
            "792cce6a91cb4fbdb39a829168b8d77a",
            "66deb0ce078446fda52ad66ebfceb3d4",
            "993db2903cab423dbecb32a3dd4cb26c",
            "614d1d10c5fd46b5ba467603dc52026e",
            "293d45e33f7143548eccb114c799caa9",
            "0f00bb9e0d2d43cfb22f9fd4238b7092",
            "c26f0a13cb5345dabe14aa299bef296b",
            "43d440a6d0aa410d8d910238291aa1e8",
            "96f0dd17eb134f6d82ac13a948739dcb",
            "1deb5b37670b40bcb050c19b913af3c2",
            "0572e86c8da3443fa4b37e835bef21a4",
            "3cdd65b8b4944583b6b1dedf2f120eb2",
            "c1e65ecd64c946c8a02c5fcce3efb5d0",
            "79ba7084f0084958b0f2921379856899",
            "6db966099fdf4364930a3a9283a20f2a",
            "0853b2621cc44531a88d7e00417d812b",
            "0c98c5414519401a8b662f06d2757e73",
            "8b44407dc1234070874ff86dc8965f01",
            "48e7d484489f4dcd97603fe2c4b0e9e8",
            "3e6eaf8fa2ad479da8d8be9bbac1237f",
            "d67c3df01e4e4d92983f06c26560cde8",
            "63d0e946289a490fadd14a73d9735604",
            "b821ec5af006453a835f93c1bcd65292",
            "5d2107f14ad64964890916f451af86f2",
            "d45f125223504cb39b07621cfd325fd4",
            "b3cda01c19144229bb4bc0536ab7c578",
            "06eb5668fc574a0dac13f8bbdb06680f",
            "e5691d659a5049d996de42216f33ece7",
            "a5eb436a23ab40d0951a8d947634e7d1",
            "9233c7b599824142a8d2cf1810c868a7",
            "e044571c13e445409c0ae56031ba164c",
            "41ab45e72c5843f88c8ab7b1224600dd",
            "262644632c0d453f9094271f0df88dc5",
            "af3b1ab6a34c436dab24382a91bfc5cc",
            "8f507492379143e0a41317cd89d806f5",
            "a67bb6314f60489f9075e4cac75ff273",
            "3d651afbb91845ea9ac17b5fe3276d6a",
            "a4fa9c8a6038400086b1adfdd6bd2a55",
            "dc72e05be2854a19b4868432eb058e24",
            "6ffcd85dd0e94651aab6a15bafe3ee32",
            "2f13ef86f6bf446e909e5cf122d76bf5",
            "cf136179ed324817b3af35cd2c8cfb5e",
            "69103b7075e54b6a8175c4ceb8c5e903",
            "cc504f7824f346c398c69663e811872d",
            "413708a77b024c57bae6c229a59a372c",
            "341bea3430fc4eeaa943118768d58d38",
            "3a6a64b9a1274d6a803d8e57075a7d8e",
            "44763f4b1745400ba706f9afcb9a2338",
            "f9815cbf367d4f27bf0f7a8baa0a268f",
            "a1512da8a42e40c9be4aef79967d7c27",
            "a3e957510f5b4215ac60da1c8b94e0c6",
            "bd3c992124fa4da899b712a9a22af9f5",
            "440fd6a5834f44acbb32c362fce749a4",
            "0657445e0f3c409090bcb8cb9bb187a8",
            "a90fed65ed964ad48498acc661458fd8",
            "798a928097514c5fa8da79c9c266f858"
          ]
        },
        "id": "96128783",
        "outputId": "48f30c88-f023-47ac-9482-ddeae94db21c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.12/dist-packages (22.5)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: whisper-openai in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.12/dist-packages (15.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.1.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (10.8.0)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python==0.2.0->whisper-openai) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 186MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e5e34f19d884885a3c38977b0705a7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a71987446a3d4206b49abcd98bb1874a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66deb0ce078446fda52ad66ebfceb3d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1e65ecd64c946c8a02c5fcce3efb5d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d2107f14ad64964890916f451af86f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f507492379143e0a41317cd89d806f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-zwnj-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "341bea3430fc4eeaa943118768d58d38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-4 (run_polling):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 105, in add_signal_handler\n",
            "    signal.set_wakeup_fd(self._csock.fileno())\n",
            "ValueError: set_wakeup_fd only works in main thread of the main interpreter\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\", line 839, in run_polling\n",
            "    return self.__run(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\", line 1044, in __run\n",
            "    loop.add_signal_handler(sig, self._raise_system_exit)\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 107, in add_signal_handler\n",
            "    raise RuntimeError(str(exc))\n",
            "RuntimeError: set_wakeup_fd only works in main thread of the main interpreter\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ربات فعال شد! برای توقف، کلیدهای CTRL+C را فشار دهید.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.12/threading.py:1077: RuntimeWarning: coroutine 'Updater.start_polling' was never awaited\n",
            "  self._invoke_excepthook(self)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Install necessary libraries and upgrade conflicting ones for dependency resolution\n",
        "!pip install --upgrade python-telegram-bot nest-asyncio whisper-openai pytube openai python-dotenv sentence-transformers transformers torch\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import sqlite3\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import whisper\n",
        "import tempfile\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "import asyncio\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "# import threading # Import threading - Removed threading as it conflicts with asyncio in this context\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops, necessary for running asyncio in environments like Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio for audio loading\n",
        "\n",
        "# تنظیمات لاگ‌گیری\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# توکن ربات و آیدی کانال — این مقادیر را جایگزین کرده‌اید\n",
        "BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\") # Corrected variable name\n",
        "SPONSOR_CHANNEL = os.environ.get(\"SPONSOR_CHANNEL\", \"@Radio_Zhelofen\") # Corrected variable name\n",
        "\n",
        "# --- پایگاه داده برای مدیریت کاربران و سهمیه ---\n",
        "DB_NAME = 'users.db'\n",
        "\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        add_user(user_id) # Ensure user exists before returning default\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_user(user_id):\n",
        "     conn = None\n",
        "     try:\n",
        "         conn = sqlite3.connect(DB_NAME)\n",
        "         c = conn.cursor()\n",
        "         c.execute(\"INSERT OR IGNORE INTO users (user_id, usage_count, referral_count) VALUES (?, 0, 0)\", (user_id,))\n",
        "         conn.commit()\n",
        "         logger.info(f\"User {user_id} added to DB if not exists.\")\n",
        "     except sqlite3.Error as e:\n",
        "         logger.error(f\"Error adding user {user_id} to DB: {e}\")\n",
        "     finally:\n",
        "         if conn:\n",
        "             conn.close()\n",
        "\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET usage_count = usage_count + 1 WHERE user_id = ?\", (user_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- بررسی عضویت در کانال ---\n",
        "async def check_channel_membership(user_id, context: ContextTypes.DEFAULT_TYPE):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"خطا در بررسی عضویت: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Load the Whisper model once at the beginning\n",
        "whisper_model = None\n",
        "try:\n",
        "    # Consider loading a smaller model if memory is an issue, e.g., \"base.en\" or \"small\"\n",
        "    # Also consider specifying device=\"cuda\" if a GPU is available and you have torch with CUDA\n",
        "    whisper_model = whisper.load_model(\"large\", device=\"cpu\") # Changed model to \"large\" and device to \"cpu\"\n",
        "    logger.info(\"Whisper model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading Whisper model: {e}\")\n",
        "\n",
        "\n",
        "# Load a text analysis model using Hugging Face pipeline\n",
        "text_analyzer = None\n",
        "try:\n",
        "    # Using a general-purpose text classification model for Persian as a placeholder.\n",
        "    # Finding a specific legal text analysis model for Persian in open-source is difficult.\n",
        "    # This model is a general Persian text classification model. Its suitability for legal analysis is limited.\n",
        "    # Replace with a more suitable model if one is found.\n",
        "    # Using a valid Persian text classification model from Hugging Face\n",
        "    model_name = \"HooshvareLab/bert-fa-zwnj-base\" # Corrected model name - using a general purpose Persian BERT model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    # The pipeline task might need adjustment depending on the specific model's intended use (e.g., sentiment-analysis, sequence-classification)\n",
        "    # For a general BERT model, 'feature-extraction' or 'fill-mask' might be more appropriate if not fine-tuned for a specific task.\n",
        "    # Assuming a classification task for now, but this might need refinement based on the desired legal analysis.\n",
        "    text_analyzer = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "    logger.info(\"Text analysis model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading text analysis model: {e}\")\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"دستور /start — بررسی عضویت در کانال و نمایش منو\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    add_user(user_id) # Ensure user exists for quota checks\n",
        "\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "        await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # If user is a member, show the main menu\n",
        "    keyboard = [\n",
        "        [\"🎤 تبدیل صوت به متن\", \"📝 تحلیل حقوقی متن\"],\n",
        "        [\"📄 ساخت قرارداد\", \"ℹ️ راهنما\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"🔰 به ربات هوشمند حقوقی خوش آمدید!\\n\\n\"\n",
        "        \"لطفاً یکی از گزینه‌های زیر را انتخاب کنید:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های صوتی و تبدیل به متن\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "    # Then check usage quota\n",
        "    user_data = get_user_data(user_id)\n",
        "    FREE_USAGE_LIMIT = 5\n",
        "    REFERRAL_REQUIRED = 5\n",
        "\n",
        "    if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "        await update.message.reply_text(\n",
        "            f\"❌ سهمیه رایگان {FREE_USAGE_LIMIT} تایی شما به پایان رسید.\\n\"\n",
        "            f\"برای ادامه استفاده، باید {REFERRAL_REQUIRED} کاربر را معرفی کنید.\\n\"\n",
        "            \"برای دریافت لینک دعوت خود، با مدیر تماس بگیرید.\" # Simplified message as referral link generation is not fully implemented\n",
        "        )\n",
        "        return\n",
        "\n",
        "    if whisper_model is None:\n",
        "        await update.message.reply_text(\"❌ متأسفانه مدل تبدیل صوت به متن بارگذاری نشده است. لطفاً به مدیر ربات اطلاع دهید.\")\n",
        "        return\n",
        "\n",
        "    await update.message.reply_text(\"✅ پیام صوتی شما دریافت شد. در حال پردازش...\")\n",
        "\n",
        "    audio_path = None # Initialize audio_path to None\n",
        "    try:\n",
        "        voice_file = await update.message.voice.get_file()\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as tmp_file:\n",
        "            audio_path = tmp_file.name\n",
        "\n",
        "        await voice_file.download_to_drive(audio_path)\n",
        "\n",
        "        # Added error handling around transcription\n",
        "        try:\n",
        "            # Consider adding options like fp16=False if not using GPU or seeing issues\n",
        "            result = whisper_model.transcribe(audio_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"خطا در استخراج متن\")\n",
        "        except Exception as transcribe_error:\n",
        "            logger.error(f\"Error during Whisper transcription: {transcribe_error}\")\n",
        "            transcribed_text = \"❌ خطایی در تبدیل پیام صوتی به متن رخ داد.\"\n",
        "\n",
        "\n",
        "        increment_usage(user_id)\n",
        "        user_data = get_user_data(user_id)\n",
        "        remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "        response_text = f\"📝 متن استخراج شده:\\n\\n{transcribed_text}\\n\\n\"\n",
        "        if remaining_uses > 0:\n",
        "             response_text += f\"🔢 شما {remaining_uses} استفاده رایگان دیگر دارید.\"\n",
        "        else:\n",
        "             response_text += f\"💡 سهمیه رایگان شما به پایان رسید. برای ادامه استفاده، لطفا {REFERRAL_REQUIRED} کاربر را معرفی کنید.\"\n",
        "\n",
        "        await update.message.reply_text(response_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling voice message: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطایی در پردازش پیام صوتی شما رخ داد.\")\n",
        "    finally:\n",
        "        # Ensure the temporary file is deleted\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                os.unlink(audio_path)\n",
        "                logger.info(f\"Temporary file deleted: {audio_path}\")\n",
        "            except Exception as cleanup_error:\n",
        "                logger.error(f\"Error deleting temporary file {audio_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های متنی و تحلیل حقوقی\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    user_text = update.message.text\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "\n",
        "    if user_text == \"🎤 تبدیل صوت به متن\":\n",
        "        await update.message.reply_text(\"لطفاً پیام صوتی خود را ارسال کنید.\")\n",
        "    elif user_text == \"📝 تحلیل حقوقی متن\":\n",
        "        await update.message.reply_text(\"لطفاً متن حقوقی خود را برای تحلیل ارسال کنید.\")\n",
        "    elif user_text == \"📄 ساخت قرارداد\":\n",
        "        await update.message.reply_text(\"این قابلیت به زودی فعال خواهد شد.\")\n",
        "    elif user_text == \"ℹ️ راهنما\":\n",
        "         await update.message.reply_text(\n",
        "             \"📚 **راهنمای استفاده از ربات:**\\n\\n\"\n",
        "             \"• برای تبدیل صوت به متن، گزینه '🎤 تبدیل صوت به متن' را انتخاب کرده و سپس پیام صوتی خود را ارسال کنید.\\n\"\n",
        "             \"• برای تحلیل متن حقوقی، گزینه '📝 تحلیل حقوقی متن' را انتخاب کرده و سپس متن مورد نظر را ارسال کنید.\\n\"\n",
        "             \"• قابلیت '📄 ساخت قرارداد' به زودی اضافه خواهد شد.\\n\"\n",
        "             \"• برای بازگشت به منوی اصلی، دستور /start را ارسال کنید.\"\n",
        "         )\n",
        "    elif text_analyzer is None:\n",
        "        await update.message.reply_text(\"❌ متأسفانه مدل تحلیل متن بارگذاری نشده است. لطفاً به مدیر ربات اطلاع دهید.\")\n",
        "    else:\n",
        "        # Apply usage quota check for text analysis\n",
        "        user_data = get_user_data(user_id)\n",
        "        FREE_USAGE_LIMIT = 5\n",
        "        REFERRAL_REQUIRED = 5\n",
        "\n",
        "        if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "            await update.message.reply_text(\n",
        "                f\"❌ سهمیه رایگان {FREE_USAGE_LIMIT} تایی شما به پایان رسید.\\n\"\n",
        "                f\"برای ادامه استفاده، باید {REFERRAL_REQUIRED} کاربر را معرفی کنید.\\n\"\n",
        "                \"برای دریافت لینک دعوت خود، با مدیر تماس بگیرید.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "\n",
        "        await update.message.reply_text(\"✅ متن شما دریافت شد. در حال تحلیل حقوقی...\")\n",
        "        formatted_result = \"⚠️ تحلیل متن با مشکلی مواجه شد یا نتیجه‌ای در دسترس نیست.\" # Initialize formatted_result\n",
        "        try:\n",
        "            # Added error handling around text analysis\n",
        "            try:\n",
        "                analysis_result = text_analyzer(user_text)\n",
        "                if analysis_result and isinstance(analysis_result, list) and len(analysis_result) > 0:\n",
        "                     formatted_result = f\"📊 نتیجه تحلیل:\\n\\n\"\n",
        "                     # The output format depends on the specific model.\n",
        "                     # For a classification model, it might be a list of labels and scores.\n",
        "                     # Adjust this formatting based on the actual output of the chosen Persian model.\n",
        "                     # Example formatting assuming a list of dicts with 'label' and 'score':\n",
        "                     for item in analysis_result:\n",
        "                          # Need to handle potential list of lists or other structures depending on the model\n",
        "                          if isinstance(item, list):\n",
        "                              for sub_item in item:\n",
        "                                   formatted_result += f\"- {sub_item.get('label', 'N/A')}: {sub_item.get('score', 0):.2f}\\n\"\n",
        "                          elif isinstance(item, dict):\n",
        "                               formatted_result += f\"- {item.get('label', 'N/A')}: {item.get('score', 0):.2f}\\n\"\n",
        "                          else:\n",
        "                               formatted_result += f\"- {item}\\n\" # Fallback for other output types\n",
        "\n",
        "\n",
        "                else:\n",
        "                     formatted_result = \"⚠️ تحلیل متن با مشکلی مواجه شد یا نتیجه‌ای در دسترس نیست.\"\n",
        "            except Exception as analysis_model_error:\n",
        "                 logger.error(f\"Error during text analysis model processing: {analysis_model_error}\")\n",
        "                 formatted_result = \"❌ خطایی در پردازش تحلیل متن توسط مدل رخ داد.\"\n",
        "\n",
        "\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id)\n",
        "            remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "            response_text = f\"{formatted_result}\\n\\n\"\n",
        "            if remaining_uses > 0:\n",
        "                 response_text += f\"🔢 شما {remaining_uses} استفاده رایگان دیگر دارید.\"\n",
        "            else:\n",
        "                 response_text += f\"💡 سهمیه رایگان شما به پایان رسید. برای ادامه استفاده، لطفا {REFERRAL_REQUIRED} کاربر را معرفی کنید.\"\n",
        "\n",
        "\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"General error handling text message for analysis: {e}\")\n",
        "            # Avoid sending a generic error if a more specific one was already generated\n",
        "            if \"خطایی در پردازش تحلیل متن توسط مدل رخ داد\" not in formatted_result and \\\n",
        "               \"⚠️ تحلیل متن با مشکلی مواجه شد\" not in formatted_result:\n",
        "                 await update.message.reply_text(\"❌ خطایی در پردازش درخواست تحلیل متن شما رخ داد.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"تابع اصلی برای راه‌اندازی ربات\"\"\"\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE & ~filters.COMMAND, handle_voice)) # Ensure it only handles voice messages that are not commands\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)) # Ensure it only handles text messages that are not commands\n",
        "\n",
        "    print(\"✅ ربات در حال راه‌اندازی است...\")\n",
        "    # Added error handling for polling\n",
        "    try:\n",
        "        # Use asyncio.run to manage the event loop explicitly\n",
        "        asyncio.run(application.run_polling())\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"❌ ربات با خطا متوقف شد: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934f28aa"
      },
      "source": [
        "## انجام تست‌های جامع\n",
        "\n",
        "### Subtask:\n",
        "عملکرد ربات را به طور کامل تست کنید. این شامل ارسال پیام‌های صوتی، ارسال متون مختلف (حقوقی و غیرحقوقی)، بررسی پاسخ ربات به انتخاب‌های منو، و تست سناریوهای مربوط به عضویت در کانال و سهمیه استفاده است. نتایج تست را ثبت و هرگونه مشکل باقی‌مانده را شناسایی کنید."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HALl_daGMOj"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# ## تنظیمات محیط و کلیدها\n",
        "# لطفاً متغیرهای زیر را با مقادیر واقعی خود جایگزین کنید.\n",
        "\n",
        "# %%\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# تنظیم توکن ربات تلگرام شما\n",
        "os.environ['TELEGRAM_BOT_TOKEN'] = '7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc'  # توکن خود را اینجا قرار دهید\n",
        "\n",
        "# تنظیم کلید OpenAI برای دستیابی به بهترین عملکرد (اختیاری اما توصیه می‌شود)\n",
        "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'  # اگر دارید، جایگزین کنید\n",
        "\n",
        "# آدرس کانال اسپانسر (بات باید در کانال ادمین باشد)\n",
        "os.environ['SPONSOR_CHANNEL'] = '@Radio_Zhelofen'\n",
        "\n",
        "# تنظیمات مدل\n",
        "model_size = \"large\"  # برای دقت بالاتر در تشخیص گفتار"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAT61mAaN0xm"
      },
      "outputs": [],
      "source": [
        "# Redundant installation cell, removing as dependencies are handled in the first cell\n",
        "# pip install transformers==4.37.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOsluWp2OWbA"
      },
      "outputs": [],
      "source": [
        "pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9NB4OlJOfO2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "print(pipeline('sentiment-analysis')('I love this!'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww3tJuKBRwkm"
      },
      "outputs": [],
      "source": [
        "# Redundant installation cell, removing as dependencies are handled in the first cell\n",
        "# pip install nest_asyncio\n",
        "# import nest_asyncio\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# حالا کد اصلی ربات خود را اینجا اجرا کنید"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHGwyym0ML0d"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import logging\n",
        "import os\n",
        "import sqlite3\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import (\n",
        "    Application, CommandHandler, MessageHandler, filters,\n",
        "    ConversationHandler, CallbackContext, CallbackQueryHandler\n",
        ")\n",
        "import whisper\n",
        "import torch\n",
        "from pytube import YouTube\n",
        "import tempfile\n",
        "import re\n",
        "\n",
        "# تنظیمات لاگینگ\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# تنظیمات ربات\n",
        "BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN', '7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc')\n",
        "SPONSOR_CHANNEL = os.getenv('SPONSOR_CHANNEL', '@Radio_Zhelofen')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'your-openai-api-key-here')\n",
        "\n",
        "# حالت های مکالمه\n",
        "CHOOSING, TRACKING_REFERRALS = range(2)\n",
        "\n",
        "# --- پایگاه داده برای مدیریت کاربران و دعوت‌ها ---\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referred_by INTEGER,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute('''INSERT OR REPLACE INTO users\n",
        "                     (user_id, usage_count, referral_count)\n",
        "                     VALUES (?, COALESCE((SELECT usage_count FROM users WHERE user_id=?), 0) + 1,\n",
        "                             COALESCE((SELECT referral_count FROM users WHERE user_id=?), 0))''',\n",
        "                  (user_id, user_id, user_id))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect('users.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- بررسی عضویت در کانال ---\n",
        "async def check_channel_membership(user_id, context: CallbackContext):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"خطا در بررسی عضویت: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- مدیریت ویدیو و صوت ---\n",
        "async def handle_media(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    try:\n",
        "        # بررسی عضویت\n",
        "        if not await check_channel_membership(user_id, context):\n",
        "            await update.message.reply_text(\n",
        "                f\"⚠️ برای استفاده از ربات، باید در کانال اسپانسر عضو شوید:\\n{SPONSOR_CHANNEL}\\n\"\n",
        "                \"پس از عضویت، مجدد اقدام کنید.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        user_data = get_user_data(user_id)\n",
        "        if user_data['usage_count'] >= 5 and user_data['referral_count'] < 5:\n",
        "            await update.message.reply_text(\n",
        "                \"❌ سهمیه رایگان شما به پایان رسید.\\n\"\n",
        "                \"برای ادامه استفاده، باید 5 کاربر را معرفی کنید.\\n\"\n",
        "                \"از منوی اصلی گزینه 'دعوت از دوستان' را انتخاب کنید.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # پردازش رسانه\n",
        "        await update.message.reply_text(\"🎥 در حال پردازش فایل ارسالی...\")\n",
        "\n",
        "        if update.message.video:\n",
        "            file = await update.message.video.get_file()\n",
        "            suffix = '.mp4' # Assuming mp4 for video, adjust if needed\n",
        "        elif update.message.voice:\n",
        "            file = await update.message.voice.get_file()\n",
        "            suffix = '.ogg' # Assuming ogg for voice, adjust if needed\n",
        "        else:\n",
        "            await update.message.reply_text(\"⚠️ لطفا یک فایل ویدیویی یا صوتی ارسال کنید.\")\n",
        "            return\n",
        "\n",
        "        # ذخیره فایل موقت\n",
        "        file_path = None # Initialize to None\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:\n",
        "                file_path = tmp_file.name\n",
        "            await file.download_to_drive(file_path)\n",
        "\n",
        "            # تبدیل به متن\n",
        "            model = whisper.load_model(\"base\") # Consider loading this once globally\n",
        "            result = model.transcribe(file_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"خطا در استخراج متن\")\n",
        "\n",
        "            # افزایش تعداد استفاده\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id) # Get updated data\n",
        "            remaining_uses = 5 - (user_data['usage_count']) # Assuming 5 is the limit\n",
        "\n",
        "\n",
        "            # ارسال نتیجه\n",
        "            response_text = (\n",
        "                f\"📝 **متن استخراج شده:**\\n\\n{transcribed_text}\\n\\n\"\n",
        "                f\"🔢 شما {max(0, 5 - user_data['usage_count'])} استفاده رایگان دیگر دارید.\" # Display remaining uses\n",
        "            )\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as processing_error:\n",
        "            logger.error(f\"Error during media processing: {processing_error}\")\n",
        "            await update.message.reply_text(\"❌ خطایی در پردازش فایل شما رخ داد.\")\n",
        "        finally:\n",
        "            # حذف فایل موقت\n",
        "            if file_path and os.path.exists(file_path):\n",
        "                try:\n",
        "                    os.unlink(file_path)\n",
        "                    logger.info(f\"Temporary file deleted: {file_path}\")\n",
        "                except Exception as cleanup_error:\n",
        "                    logger.error(f\"Error deleting temporary file {file_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"General error in handle_media: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطای کلی در پردازش درخواست شما رخ داد.\")\n",
        "\n",
        "\n",
        "# --- سیستم دعوت دوستان ---\n",
        "async def share_invite_link(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        bot_username = (await context.bot.get_me()).username\n",
        "        invite_link = f\"https://t.me/{bot_username}?start=ref{user_id}\"\n",
        "\n",
        "        await update.message.reply_text(\n",
        "            f\"🔗 لینک دعوت اختصاصی شما:\\n\\n`{invite_link}`\\n\\n\"\n",
        "            \"این لینک را برای دوستان خود ارسال کنید. پس از عضویت و استفاده آنان، \"\n",
        "            \"سهمیه شما افزایش خواهد یافت.\",\n",
        "            parse_mode='Markdown'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error sharing invite link: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطایی در ایجاد لینک دعوت رخ داد.\")\n",
        "\n",
        "\n",
        "# --- مدیریت کاربران دعوت شده ---\n",
        "async def track_referral(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        args = context.args\n",
        "\n",
        "        if args and args[0].startswith('ref'):\n",
        "            try:\n",
        "                referrer_id = int(args[0][3:])\n",
        "                if referrer_id != user_id:\n",
        "                    add_referral(referrer_id)\n",
        "                    await update.message.reply_text(\n",
        "                        \"✅ به ربات خوش آمدید! شما با لینک دعوت یکی از کاربران وارد شدید.\"\n",
        "                    )\n",
        "            except ValueError:\n",
        "                logger.error(f\"Invalid referrer ID format: {args[0]}\")\n",
        "                # Continue without adding referral if ID is invalid\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error tracking referral: {e}\")\n",
        "                # Continue without adding referral in case of other errors\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"General error in track_referral: {e}\")\n",
        "        # No message to user for this internal tracking function\n",
        "\n",
        "\n",
        "# --- منوی اصلی ---\n",
        "async def start(update: Update, context: CallbackContext):\n",
        "    user_id = update.effective_user.id\n",
        "    try:\n",
        "        await track_referral(update, context) # Track referral on start\n",
        "\n",
        "        if not await check_channel_membership(user_id, context):\n",
        "            await update.message.reply_text(\n",
        "                f\"🔔 خوش آمدید!\\n\\n\"\n",
        "                f\"برای استفاده از ربات هوشمند حقوقی، باید در کانال اسپانسر ما عضو شوید:\\n\"\n",
        "                f\"{SPONSOR_CHANNEL}\\n\\n\"\n",
        "                f\"پس از عضویت، مجدد دستور /start را ارسال کنید.\"\n",
        "            )\n",
        "            return ConversationHandler.END\n",
        "\n",
        "        user_data = get_user_data(user_id)\n",
        "        keyboard = [\n",
        "            [InlineKeyboardButton(\"🎥 آپلود ویدیو/صوت\", callback_data=\"upload_media\")],\n",
        "            [InlineKeyboardButton(\"📝 تحلیل متن حقوقی\", callback_data=\"analyze_text\")],\n",
        "            [InlineKeyboardButton(\"📄 تنظیم قرارداد\", callback_data=\"generate_contract\")],\n",
        "            [InlineKeyboardButton(\"🔗 دعوت از دوستان\", callback_data=\"invite_friends\")],\n",
        "            [InlineKeyboardButton(\"📊 وضعیت سهمیه\", callback_data=\"usage_status\")]\n",
        "        ]\n",
        "        reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "        welcome_text = (\n",
        "            \"👋 به ربات هوشمند حقوقی خوش آمدید!\\n\\n\"\n",
        "            \"⚖️ *امکانات ربات:*\\n\"\n",
        "            \"• تبدیل ویدیو و صوت به متن با دقت بالا\\n\"\n",
        "            \"• تحلیل تخصصی متون حقوقی\\n\"\n",
        "            \"• تنظیم قراردادهای هوشمند\\n\"\n",
        "            \"• پرسش و پاسخ حقوقی\\n\\n\"\n",
        "            \"لطفاً یک گزینه را از منوی زیر انتخاب کنید:\"\n",
        "        )\n",
        "        await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')\n",
        "        return CHOOSING\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in start handler: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطایی در شروع ربات رخ داد.\")\n",
        "        return ConversationHandler.END # End conversation on error\n",
        "\n",
        "\n",
        "# --- مدیریت انتخاب های منو ---\n",
        "async def handle_menu_selection(update: Update, context: CallbackContext):\n",
        "    query = update.callback_query\n",
        "    await query.answer()\n",
        "\n",
        "    user_id = query.from_user.id\n",
        "    user_data = get_user_data(user_id)\n",
        "\n",
        "    try:\n",
        "        if query.data == \"upload_media\":\n",
        "            if user_data['usage_count'] >= 5 and user_data['referral_count'] < 5:\n",
        "                await query.edit_message_text(\n",
        "                    \"❌ سهمیه رایگان شما به پایان رسید.\\n\\n\"\n",
        "                    \"برای ادامه استفاده، باید ۵ کاربر را از طریق لینک دعوت خود به ربات معرفی کنید.\\n\\n\"\n",
        "                    \"از گزینه 'دعوت از دوستان' در منو استفاده کنید.\"\n",
        "                )\n",
        "                return CHOOSING\n",
        "            else:\n",
        "                await query.edit_message_text(\n",
        "                    \"🎥 لطفاً ویدیو یا پیام صوتی خود را ارسال کنید.\\n\\n\"\n",
        "                    \"✅ ربات از فرمت‌های مختلف پشتیبانی می‌کند.\\n\"\n",
        "                    \"⏱️ پردازش فایل ممکن است چند لحظه زمان ببرد.\"\n",
        "                )\n",
        "                return CHOOSING\n",
        "\n",
        "        elif query.data == \"invite_friends\":\n",
        "            bot_username = (await context.bot.get_me()).username\n",
        "            invite_link = f\"https://t.me/{bot_username}?start=ref{user_id}\"\n",
        "\n",
        "            await query.edit_message_text(\n",
        "                f\"👥 **سیستم دعوت از دوستان**\\n\\n\"\n",
        "                f\"🔗 لینک اختصاصی شما:\\n`{invite_link}`\\n\\n\"\n",
        "                f\"📊 وضعیت فعلی:\\n\"\n",
        "                f\"• تعداد استفاده‌ها: {user_data['usage_count']}/5\\n\"\n",
        "                f\"• دوستان invited: {user_data['referral_count']}/5\\n\\n\"\n",
        "                f\"✅ با هر ۵ دعوت موفق، ۵ استفاده رایگان جدید دریافت می‌کنید.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            return CHOOSING\n",
        "\n",
        "        elif query.data == \"usage_status\":\n",
        "            await query.edit_message_text(\n",
        "                f\"📊 **وضعیت سهمیه شما**\\n\\n\"\n",
        "                f\"• تعداد استفاده‌ها: {user_data['usage_count']}/5\\n\"\n",
        "                f\"• دوستان invited: {user_data['referral_count']}/5\\n\\n\"\n",
        "                f\"🔁 پس از اتمام سهمیه، با دعوت از دوستان می‌توانید به استفاده ادامه دهید.\",\n",
        "                parse_mode='Markdown'\n",
        "            )\n",
        "            return CHOOSING\n",
        "\n",
        "        else:\n",
        "            await query.edit_message_text(\"🛠️ این قابلیت به زودی فعال خواهد شد.\")\n",
        "            return CHOOSING\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in handle_menu_selection: {e}\")\n",
        "        await query.edit_message_text(\"❌ خطایی در پردازش انتخاب شما رخ داد.\")\n",
        "        return CHOOSING # Stay in CHOOSING state\n",
        "\n",
        "\n",
        "# --- تابع اصلی ---\n",
        "def main():\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    # هندلرهای مکالمه\n",
        "    conv_handler = ConversationHandler(\n",
        "        entry_points=[CommandHandler('start', start)],\n",
        "        states={\n",
        "            CHOOSING: [\n",
        "                CallbackQueryHandler(handle_menu_selection),\n",
        "                MessageHandler(filters.VIDEO | filters.VOICE, handle_media)\n",
        "            ]\n",
        "        },\n",
        "        fallbacks=[CommandHandler('start', start)]\n",
        "    )\n",
        "\n",
        "    application.add_handler(conv_handler)\n",
        "    # The following line is redundant because handle_media is already handled in the ConversationHandler\n",
        "    # application.add_handler(MessageHandler(filters.VIDEO | filters.VOICE, handle_media))\n",
        "\n",
        "    print(\"✅ ربات فعال شد! برای توقف، کلیدهای CTRL+C را فشار دهید.\")\n",
        "    try:\n",
        "        application.run_polling()\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"❌ ربات با خطا متوقف شد: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaZvRmj0UQyn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3CNId8HUarK"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade python-telegram-bot whisper-openai transformers torch sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayzaH-tNYCip"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# نصب کتابخانه لازم (در صورت نبود)\n",
        "# !pip install transformers torch torchaudio datasets\n",
        "\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio\n",
        "\n",
        "# تعیین دستگاه پردازش (از GPU استفاده کن اگر در دسترس باشد)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# بارگذاری پردازشگر و مدل large-v3\n",
        "model_name = \"openai/whisper-large-v3\"\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "# اختیاری: برای تشخیص خودکار زبان، این شناسه‌ها را None بگذار\n",
        "model.config.forced_decoder_ids = None\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    تابع برای تبدیل صوت به متن\n",
        "    \"\"\"\n",
        "    # بارگذاری فایل صوتی\n",
        "    # TODO: Load the audio file from audio_path using a library like torchaudio or librosa.\n",
        "    # Example with torchaudio:\n",
        "    # waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    # audio_sample = {\"array\": waveform.squeeze().numpy(), \"sampling_rate\": sample_rate}\n",
        "\n",
        "    # For now, using a placeholder for audio_sample\n",
        "    # Replace this with actual audio loading\n",
        "    audio_sample = None\n",
        "    print(f\"Placeholder: Loading audio from {audio_path}\") # Placeholder print statement\n",
        "\n",
        "    if audio_sample is None:\n",
        "        print(\"Error: Audio sample not loaded. Please implement audio loading.\")\n",
        "        return \"Error: Could not load audio.\"\n",
        "\n",
        "\n",
        "    # پردازش ویژگی‌های ورودی\n",
        "    input_features = processor(\n",
        "        audio_sample[\"array\"],\n",
        "        sampling_rate=audio_sample[\"sampling_rate\"],\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "\n",
        "    # تولید شناسه‌های توکن\n",
        "    predicted_ids = model.generate(input_features)\n",
        "\n",
        "    # دیکد کردن به متن\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "    return transcription[0]\n",
        "\n",
        "# استفاده از تابع\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file_path = \"path/to/your/audio/file.wav\"  # مسیر فایل صوتی خود را اینجا قرار دهید\n",
        "    # TODO: Replace the placeholder audio_file_path with the actual path to your audio file.\n",
        "    text_result = transcribe_audio(audio_file_path)\n",
        "    print(\"متن استخراج شده:\")\n",
        "    print(text_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "3a62a4b3",
        "outputId": "a5393f10-2360-4e10-931d-85c381cce2ce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'telegram'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2656183374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtelegram\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtelegram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommandHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessageHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContextTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'telegram'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import logging\n",
        "import sqlite3\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "import whisper\n",
        "import tempfile\n",
        "from transformers import pipeline\n",
        "import asyncio\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops, necessary for running asyncio in environments like Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "# import torchaudio # Uncomment this line if you want to use torchaudio for audio loading\n",
        "\n",
        "# تنظیمات لاگ‌گیری\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# توکن ربات و آیدی کانال — این مقادیر را جایگزین کرده‌اید\n",
        "BOT_TOKEN = os.environ.get(\"TELEGRAM_BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\") # Corrected variable name\n",
        "SPONSOR_CHANNEL = os.environ.get(\"SPONSOR_CHANNEL\", \"@Radio_Zhelofen\") # Corrected variable name\n",
        "\n",
        "# --- پایگاه داده برای مدیریت کاربران و سهمیه ---\n",
        "DB_NAME = 'users.db'\n",
        "\n",
        "def init_db():\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                     (user_id INTEGER PRIMARY KEY,\n",
        "                      usage_count INTEGER DEFAULT 0,\n",
        "                      referral_count INTEGER DEFAULT 0)''')\n",
        "        conn.commit()\n",
        "        logger.info(\"Database initialized.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error initializing database: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "def get_user_data(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT usage_count, referral_count FROM users WHERE user_id=?\", (user_id,))\n",
        "        result = c.fetchone()\n",
        "        if result:\n",
        "            return {'usage_count': result[0], 'referral_count': result[1]}\n",
        "        add_user(user_id) # Ensure user exists before returning default\n",
        "        return {'usage_count': 0, 'referral_count': 0}\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error retrieving user data for user {user_id}: {e}\")\n",
        "        return {'usage_count': 0, 'referral_count': 0} # Return default in case of error\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_user(user_id):\n",
        "     conn = None\n",
        "     try:\n",
        "         conn = sqlite3.connect(DB_NAME)\n",
        "         c = conn.cursor()\n",
        "         c.execute(\"INSERT OR IGNORE INTO users (user_id, usage_count, referral_count) VALUES (?, 0, 0)\", (user_id,))\n",
        "         conn.commit()\n",
        "         logger.info(f\"User {user_id} added to DB if not exists.\")\n",
        "     except sqlite3.Error as e:\n",
        "         logger.error(f\"Error adding user {user_id} to DB: {e}\")\n",
        "     finally:\n",
        "         if conn:\n",
        "             conn.close()\n",
        "\n",
        "\n",
        "def increment_usage(user_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET usage_count = usage_count + 1 WHERE user_id = ?\", (user_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Usage count incremented for user {user_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error incrementing usage for user {user_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def add_referral(referrer_id):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DB_NAME)\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"UPDATE users SET referral_count = referral_count + 1 WHERE user_id = ?\", (referrer_id,))\n",
        "        conn.commit()\n",
        "        logger.info(f\"Referral count incremented for user {referrer_id}.\")\n",
        "    except sqlite3.Error as e:\n",
        "        logger.error(f\"Error adding referral for user {referrer_id}: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# --- بررسی عضویت در کانال ---\n",
        "async def check_channel_membership(user_id, context: ContextTypes.DEFAULT_TYPE):\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        return member.status in ['member', 'administrator', 'creator']\n",
        "    except Exception as e:\n",
        "        logger.error(f\"خطا در بررسی عضویت: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Load the Whisper model once at the beginning\n",
        "whisper_model = None\n",
        "try:\n",
        "    # Consider loading a smaller model if memory is an issue, e.g., \"base.en\" or \"small\"\n",
        "    # Also consider specifying device=\"cuda\" if a GPU is available and you have torch with CUDA\n",
        "    whisper_model = whisper.load_model(\"base\")\n",
        "    logger.info(\"Whisper model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading Whisper model: {e}\")\n",
        "\n",
        "\n",
        "# Load a text analysis model using Hugging Face pipeline\n",
        "text_analyzer = None\n",
        "try:\n",
        "    # Using a general-purpose text classification model for Persian as a placeholder.\n",
        "    # Finding a specific legal text analysis model for Persian in open-source is difficult.\n",
        "    # This model is a general Persian text classification model. Its suitability for legal analysis is limited.\n",
        "    # Replace with a more suitable model if one is found.\n",
        "    text_analyzer = pipeline(\"text-classification\", model=\"persiannlp/ParsBert-Political-Text-Classification\") # Example Persian text classification model - replace if needed\n",
        "    logger.info(\"Text analysis model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error loading text analysis model: {e}\")\n",
        "\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"دستور /start — بررسی عضویت در کانال و نمایش منو\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    add_user(user_id) # Ensure user exists for quota checks\n",
        "\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "        await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # If user is a member, show the main menu\n",
        "    keyboard = [\n",
        "        [\"🎤 تبدیل صوت به متن\", \"📝 تحلیل حقوقی متن\"],\n",
        "        [\"📄 ساخت قرارداد\", \"ℹ️ راهنما\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"🔰 به ربات هوشمند حقوقی خوش آمدید!\\n\\n\"\n",
        "        \"لطفاً یکی از گزینه‌های زیر را انتخاب کنید:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های صوتی و تبدیل به متن\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "    # Then check usage quota\n",
        "    user_data = get_user_data(user_id)\n",
        "    FREE_USAGE_LIMIT = 5\n",
        "    REFERRAL_REQUIRED = 5\n",
        "\n",
        "    if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "        await update.message.reply_text(\n",
        "            f\"❌ سهمیه رایگان {FREE_USAGE_LIMIT} تایی شما به پایان رسید.\\n\"\n",
        "            f\"برای ادامه استفاده، باید {REFERRAL_REQUIRED} کاربر را معرفی کنید.\\n\"\n",
        "            \"برای دریافت لینک دعوت خود، با مدیر تماس بگیرید.\" # Simplified message as referral link generation is not fully implemented\n",
        "        )\n",
        "        return\n",
        "\n",
        "    if whisper_model is None:\n",
        "        await update.message.reply_text(\"❌ متأسفانه مدل تبدیل صوت به متن بارگذاری نشده است. لطفاً به مدیر ربات اطلاع دهید.\")\n",
        "        return\n",
        "\n",
        "    await update.message.reply_text(\"✅ پیام صوتی شما دریافت شد. در حال پردازش...\")\n",
        "\n",
        "    audio_path = None # Initialize audio_path to None\n",
        "    try:\n",
        "        voice_file = await update.message.voice.get_file()\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.ogg') as tmp_file:\n",
        "            audio_path = tmp_file.name\n",
        "\n",
        "        await voice_file.download_to_drive(audio_path)\n",
        "\n",
        "        # Added error handling around transcription\n",
        "        try:\n",
        "            # Consider adding options like fp16=False if not using GPU or seeing issues\n",
        "            result = whisper_model.transcribe(audio_path, language='fa')\n",
        "            transcribed_text = result.get(\"text\", \"خطا در استخراج متن\")\n",
        "        except Exception as transcribe_error:\n",
        "            logger.error(f\"Error during Whisper transcription: {transcribe_error}\")\n",
        "            transcribed_text = \"❌ خطایی در تبدیل پیام صوتی به متن رخ داد.\"\n",
        "\n",
        "\n",
        "        increment_usage(user_id)\n",
        "        user_data = get_user_data(user_id)\n",
        "        remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "        response_text = f\"📝 متن استخراج شده:\\n\\n{transcribed_text}\\n\\n\"\n",
        "        if remaining_uses > 0:\n",
        "             response_text += f\"🔢 شما {remaining_uses} استفاده رایگان دیگر دارید.\"\n",
        "        else:\n",
        "             response_text += f\"💡 سهمیه رایگان شما به پایان رسید. برای ادامه استفاده، لطفا {REFERRAL_REQUIRED} کاربر را معرفی کنید.\"\n",
        "\n",
        "        await update.message.reply_text(response_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error handling voice message: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطایی در پردازش پیام صوتی شما رخ داد.\")\n",
        "    finally:\n",
        "        # Ensure the temporary file is deleted\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                os.unlink(audio_path)\n",
        "                logger.info(f\"Temporary file deleted: {audio_path}\")\n",
        "            except Exception as cleanup_error:\n",
        "                logger.error(f\"Error deleting temporary file {audio_path}: {cleanup_error}\")\n",
        "\n",
        "\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های متنی و تحلیل حقوقی\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "    user_text = update.message.text\n",
        "\n",
        "    # Check membership first\n",
        "    if not await check_channel_membership(user_id, context):\n",
        "         await update.message.reply_text(\n",
        "            f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "            f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "            \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "        )\n",
        "         return\n",
        "\n",
        "\n",
        "    if user_text == \"🎤 تبدیل صوت به متن\":\n",
        "        await update.message.reply_text(\"لطفاً پیام صوتی خود را ارسال کنید.\")\n",
        "    elif user_text == \"📝 تحلیل حقوقی متن\":\n",
        "        await update.message.reply_text(\"لطفاً متن حقوقی خود را برای تحلیل ارسال کنید.\")\n",
        "    elif user_text == \"📄 ساخت قرارداد\":\n",
        "        await update.message.reply_text(\"این قابلیت به زودی فعال خواهد شد.\")\n",
        "    elif user_text == \"ℹ️ راهنما\":\n",
        "         await update.message.reply_text(\n",
        "             \"📚 **راهنمای استفاده از ربات:**\\n\\n\"\n",
        "             \"• برای تبدیل صوت به متن، گزینه '🎤 تبدیل صوت به متن' را انتخاب کرده و سپس پیام صوتی خود را ارسال کنید.\\n\"\n",
        "             \"• برای تحلیل متن حقوقی، گزینه '📝 تحلیل حقوقی متن' را انتخاب کرده و سپس متن مورد نظر را ارسال کنید.\\n\"\n",
        "             \"• قابلیت '📄 ساخت قرارداد' به زودی اضافه خواهد شد.\\n\"\n",
        "             \"• برای بازگشت به منوی اصلی، دستور /start را ارسال کنید.\"\n",
        "         )\n",
        "    elif text_analyzer is None:\n",
        "        await update.message.reply_text(\"❌ متأسفانه مدل تحلیل متن بارگذاری نشده است. لطفاً به مدیر ربات اطلاع دهید.\")\n",
        "    else:\n",
        "        # Apply usage quota check for text analysis\n",
        "        user_data = get_user_data(user_id)\n",
        "        FREE_USAGE_LIMIT = 5\n",
        "        REFERRAL_REQUIRED = 5\n",
        "\n",
        "        if user_data['usage_count'] >= FREE_USAGE_LIMIT and user_data['referral_count'] < REFERRAL_REQUIRED:\n",
        "            await update.message.reply_text(\n",
        "                f\"❌ سهمیه رایگان {FREE_USAGE_LIMIT} تایی شما به پایان رسید.\\n\"\n",
        "                f\"برای ادامه استفاده، باید {REFERRAL_REQUIRED} کاربر را معرفی کنید.\\n\"\n",
        "                \"برای دریافت لینک دعوت خود، با مدیر تماس بگیرید.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "\n",
        "        await update.message.reply_text(\"✅ متن شما دریافت شد. در حال تحلیل حقوقی...\")\n",
        "        formatted_result = \"⚠️ تحلیل متن با مشکلی مواجه شد یا نتیجه‌ای در دسترس نیست.\" # Initialize formatted_result\n",
        "        try:\n",
        "            # Added error handling around text analysis\n",
        "            try:\n",
        "                analysis_result = text_analyzer(user_text)\n",
        "                if analysis_result and isinstance(analysis_result, list) and len(analysis_result) > 0:\n",
        "                     formatted_result = f\"📊 نتیجه تحلیل:\\n\\n\"\n",
        "                     # The output format depends on the specific model.\n",
        "                     # For a classification model, it might be a list of labels and scores.\n",
        "                     # Adjust this formatting based on the actual output of the chosen Persian model.\n",
        "                     # Example formatting assuming a list of dicts with 'label' and 'score':\n",
        "                     for item in analysis_result:\n",
        "                          # Need to handle potential list of lists or other structures depending on the model\n",
        "                          if isinstance(item, list):\n",
        "                              for sub_item in item:\n",
        "                                   formatted_result += f\"- {sub_item.get('label', 'N/A')}: {sub_item.get('score', 0):.2f}\\n\"\n",
        "                          elif isinstance(item, dict):\n",
        "                               formatted_result += f\"- {item.get('label', 'N/A')}: {item.get('score', 0):.2f}\\n\"\n",
        "                          else:\n",
        "                               formatted_result += f\"- {item}\\n\" # Fallback for other output types\n",
        "\n",
        "\n",
        "                else:\n",
        "                     formatted_result = \"⚠️ تحلیل متن با مشکلی مواجه شد یا نتیجه‌ای در دسترس نیست.\"\n",
        "            except Exception as analysis_model_error:\n",
        "                 logger.error(f\"Error during text analysis model processing: {analysis_model_error}\")\n",
        "                 formatted_result = \"❌ خطایی در پردازش تحلیل متن توسط مدل رخ داد.\"\n",
        "\n",
        "\n",
        "            increment_usage(user_id)\n",
        "            user_data = get_user_data(user_id)\n",
        "            remaining_uses = max(0, FREE_USAGE_LIMIT - user_data['usage_count'])\n",
        "\n",
        "            response_text = f\"{formatted_result}\\n\\n\"\n",
        "            if remaining_uses > 0:\n",
        "                 response_text += f\"🔢 شما {remaining_uses} استفاده رایگان دیگر دارید.\"\n",
        "            else:\n",
        "                 response_text += f\"💡 سهمیه رایگان شما به پایان رسید. برای ادامه استفاده، لطفا {REFERRAL_REQUIRED} کاربر را معرفی کنید.\"\n",
        "\n",
        "\n",
        "            await update.message.reply_text(response_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"General error handling text message for analysis: {e}\")\n",
        "            # Avoid sending a generic error if a more specific one was already generated\n",
        "            if \"خطایی در پردازش تحلیل متن توسط مدل رخ داد\" not in formatted_result and \\\n",
        "               \"⚠️ تحلیل متن با مشکلی مواجه شد\" not in formatted_result:\n",
        "                 await update.message.reply_text(\"❌ خطایی در پردازش درخواست تحلیل متن شما رخ داد.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"تابع اصلی برای راه‌اندازی ربات\"\"\"\n",
        "    init_db()\n",
        "\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE & ~filters.COMMAND, handle_voice)) # Ensure it only handles voice messages that are not commands\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text)) # Ensure it only handles text messages that are not commands\n",
        "\n",
        "    print(\"✅ ربات فعال شد! برای توقف، کلیدهای CTRL+C را فشار دهید.\")\n",
        "    # Added error handling for polling\n",
        "    try:\n",
        "        application.run_polling()\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Error during bot polling: {e}\")\n",
        "        print(f\"❌ ربات با خطا متوقف شد: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "nzciVNrhUE8A",
        "outputId": "4e25b97e-1da9-4b5e-e6f3-1f6420c1f2ae"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3582663576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# تغییر از مدل base به large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# استفاده از GPU اگر در دسترس است\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                         return _load(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                             \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                             \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2117\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m     \u001b[0m_serialization_tls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_weights_only_unpickler.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m                         \u001b[0;34mf\"Only persistent_load of storage is allowed, but got {pid[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                     )\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONG_BINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m             typed_storage = load_tensor(\n\u001b[0m\u001b[1;32m   2084\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_fake_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2049\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fake_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \"\"\"\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "# تغییر از مدل base به large\n",
        "model = whisper.load_model(\"large\", device=\"cuda\")  # استفاده از GPU اگر در دسترس است"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "mq3gyxg2MiKW",
        "outputId": "7d43f8d3-20c6-4cf9-f860-0fdb18bb4b06"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Cannot close a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_shutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3458777013.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3458777013.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# شروع ربات\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ربات فعال شد!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36mrun_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         return self.__run(\n\u001b[0m\u001b[1;32m    840\u001b[0m             updater_coroutine=self.updater.start_polling(\n\u001b[1;32m    841\u001b[0m                 \u001b[0mpoll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, bootstrap_retries, close_loop)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclose_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     def create_task(\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import logging\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, MessageHandler, filters, ContextTypes\n",
        "\n",
        "# تنظیمات لاگ‌گیری\n",
        "logging.basicConfig(format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\", level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# توکن ربات و آیدی کانال — این مقادیر را جایگزین کرده‌اید\n",
        "BOT_TOKEN = os.environ.get(\"BOT_TOKEN\", \"7693531934:AAEwCi1itefgAgdVZz_gvGLUc0DfbgkS6Tc\")\n",
        "SPONSOR_CHANNEL = \"@Radio_Zhelofen\"  # آیدی کانال اسپانسر\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"دستور /start — بررسی عضویت در کانال و نمایش منو\"\"\"\n",
        "    user_id = update.effective_user.id\n",
        "\n",
        "    # بررسی عضویت کاربر در کانال اسپانسر\n",
        "    try:\n",
        "        member = await context.bot.get_chat_member(chat_id=SPONSOR_CHANNEL, user_id=user_id)\n",
        "        if member.status not in [\"member\", \"administrator\", \"creator\"]:\n",
        "            await update.message.reply_text(\n",
        "                f\"⚠️ برای استفاده از ربات، لازم است ابتدا در کانال اسپانسر ما عضو شوید:\\n\\n\"\n",
        "                f\"🌐 {SPONSOR_CHANNEL}\\n\\n\"\n",
        "                \"پس از عضویت، مجدداً دستور /start را ارسال کنید.\"\n",
        "            )\n",
        "            return\n",
        "    except Exception as e:\n",
        "        logger.error(f\"خطا در بررسی عضویت کاربر در کانال: {e}\")\n",
        "        await update.message.reply_text(\"❌ خطایی در بررسی عضویت رخ داد. لطفاً بعداً تلاش کنید.\")\n",
        "        return\n",
        "\n",
        "    # اگر کاربر عضو کانال باشد، منوی اصلی نمایش داده می‌شود\n",
        "    keyboard = [\n",
        "        [\"🎤 تبدیل صوت به متن\", \"📝 تحلیل حقوقی متن\"],\n",
        "        [\"📄 ساخت قرارداد\", \"ℹ️ راهنما\"]\n",
        "    ]\n",
        "    reply_markup = {\"keyboard\": keyboard, \"resize_keyboard\": True}\n",
        "    await update.message.reply_text(\n",
        "        \"🔰 به ربات هوشمند حقوقی خوش آمدید!\\n\\n\"\n",
        "        \"لطفاً یکی از گزینه‌های زیر را انتخاب کنید:\",\n",
        "        reply_markup=reply_markup\n",
        "    )\n",
        "\n",
        "async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های صوتی و تبدیل به متن\"\"\"\n",
        "    # در این بخش باید کد مربوط به مدل متن‌باز تبدیل صوت به متن (مثلاً Whisper) فراخوانی شود.\n",
        "    await update.message.reply_text(\"✅ پیام صوتی شما دریافت شد. در حال پردازش...\")\n",
        "\n",
        "    # TODO: این بخش با کتابخانه‌های متن‌باز مانند Whisper تکمیل شود\n",
        "    # voice_file = await update.message.voice.get_file()\n",
        "    # transcribed_text = your_whisper_function(voice_file.file_path)\n",
        "\n",
        "    transcribed_text = \"متن نمونه استخراج شده از صوت\"  # این یک متن نمونه است\n",
        "\n",
        "    await update.message.reply_text(f\"📝 متن استخراج شده:\\n\\n{transcribed_text}\")\n",
        "\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    \"\"\"مدیریت پیام‌های متنی و تحلیل حقوقی\"\"\"\n",
        "    user_text = update.message.text\n",
        "\n",
        "    if user_text == \"🎤 تبدیل صوت به متن\":\n",
        "        await update.message.reply_text(\"لطفاً پیام صوتی خود را ارسال کنید.\")\n",
        "    elif user_text == \"📝 تحلیل حقوقی متن\":\n",
        "        await update.message.reply_text(\"لطفاً متن حقوقی خود را برای تحلیل ارسال کنید.\")\n",
        "    elif user_text == \"📄 ساخت قرارداد\":\n",
        "        await update.message.reply_text(\"این قابلیت به زودی فعال خواهد شد.\")\n",
        "    else:\n",
        "        # TODO: این بخش با مدل زبانی متن‌باز (مثلاً از Hugging Face) برای تحلیل متن تکمیل شود\n",
        "        await update.message.reply_text(\"درخواست شما دریافت شد. (تحلیل توسط هوش مصنوعی)\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"تابع اصلی برای راه‌اندازی ربات\"\"\"\n",
        "    application = Application.builder().token(BOT_TOKEN).build()\n",
        "\n",
        "    # ثبت هندلرها\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.VOICE, handle_voice))\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))\n",
        "\n",
        "    # شروع ربات\n",
        "    application.run_polling()\n",
        "    print(\"ربات فعال شد!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "oLlVgDx5Up0r",
        "outputId": "7e52ab46-1efa-41e1-9ffd-3d51eb1c02a1"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 2 (ipython-input-694587228.py, line 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-694587228.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 2\n"
          ]
        }
      ],
      "source": [
        "async def handle_media(update: Update, context: CallbackContext):\n",
        "    try:\n",
        "        # کد اصلی شما\n",
        "    except Exception as e:\n",
        "        logger.error(f\"خطا در پردازش رسانه: {e}\")\n",
        "        await update.message.reply_text(\"⚠️ متأسفانه در پردازش فایل مشکلی پیش آمد.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bed41458"
      },
      "source": [
        "# Task\n",
        "Debug the provided Python code for a Telegram bot, specifically addressing issues related to voice-to-text conversion errors, non-functional features, and general bugs. The debugging process should involve examining logs, completing incomplete code sections (voice-to-text and text analysis), reviewing message handling logic, checking membership/quota systems (if applicable), adding error handling, and performing comprehensive testing. The final response should be in Persian, explaining the root cause of the errors and why other features are not working."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5d9e60d"
      },
      "source": [
        "## بررسی لاگ‌ها و خطاهای موجود\n",
        "\n",
        "### Subtask:\n",
        "لاگ‌های خروجی سلول‌های قبلی، به خصوص `vHGwyym0ML0d` و `mq3gyxg2MiKW` را بررسی کنید تا خطاهای زمان اجرا یا هشدارهای موجود را شناسایی کنید.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2913622"
      },
      "source": [
        "## تکمیل قابلیت تبدیل صوت به متن\n",
        "\n",
        "### Subtask:\n",
        "کد مربوط به استفاده از مدل Whisper (یا مدل جایگزین) برای تبدیل فایل صوتی دریافتی از کاربر به متن را در تابع `handle_voice` پیاده‌سازی کنید.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4a5e13"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the voice-to-text conversion in the `handle_voice` function by loading the Whisper model, downloading the audio file, transcribing it, and sending the result to the user, ensuring temporary files are handled properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a8c1b01"
      },
      "source": [
        "## تکمیل قابلیت تحلیل متن حقوقی\n",
        "\n",
        "### Subtask:\n",
        "کد مربوط به استفاده از یک مدل زبانی (مانند مدل‌های Hugging Face) برای تحلیل متن حقوقی ارسالی توسط کاربر را در تابع `handle_text` پیاده‌سازی کنید.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e945eb05"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the text analysis feature using a Hugging Face model within the `handle_text` function. This involves loading a suitable model and tokenizer, processing the user's text, and sending the result back.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c0f4d33"
      },
      "source": [
        "## بررسی و اصلاح منطق مدیریت پیام‌ها\n",
        "\n",
        "### Subtask:\n",
        "اطمینان حاصل کنید که `MessageHandler` ها و `CommandHandler` ها به درستی تنظیم شده‌اند و پیام‌های مختلف (دستور `start`، پیام صوتی، پیام متنی) به توابع صحیح هدایت می‌شوند. منطق مربوط به منو و پاسخ به انتخاب‌های کاربر را بازبینی کنید.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d1c9f5"
      },
      "source": [
        "**Reasoning**:\n",
        "بررسی می‌کنم که هندلرهای پیام به درستی تعریف و به application اضافه شده‌اند و منطق مدیریت پیام‌های متنی در تابع `handle_text` صحیح است.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "375d0647"
      },
      "source": [
        "## بررسی منطق سیستم عضویت و سهمیه (در صورت استفاده)\n",
        "\n",
        "### Subtask:\n",
        "اگر از سیستم بررسی عضویت در کانال یا سهمیه استفاده می‌کنید (مانند آنچه در سلول `vHGwyym0ML0d` بود)، منطق آن را بررسی کنید و مطمئن شوید که به درستی کار می‌کند و در مکان‌های مناسب (مثلاً قبل از ارائه خدمات اصلی) بررسی می‌شود.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dce2ca8"
      },
      "source": [
        "**Reasoning**:\n",
        "بررسی می‌کنم که آیا منطق بررسی عضویت در کانال و سیستم سهمیه در کد فعلی (سلول `mq3gyxg2MiKW`) وجود دارد یا خیر. اگر وجود نداشته باشد، تصمیم می‌گیرم که آیا آن را اضافه کنم یا خیر و در صورت لزوم منطق آن را اضافه می‌کنم.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02c318e3"
      },
      "source": [
        "**Reasoning**:\n",
        "منطق بررسی عضویت در کانال و سیستم سهمیه به کد اضافه شده است. حالا باید اطمینان حاصل کنم که این منطق به درستی پیاده‌سازی شده و در مکان‌های صحیح (یعنی قبل از ارائه خدمات اصلی) بررسی می‌شود و پیام‌های مناسب به کاربر نمایش داده می‌شود.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fc9d57e"
      },
      "outputs": [],
      "source": [
        "# Run the bot code cell\n",
        "# Removed get_ipython().run_cell('96128783') to avoid running main multiple times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94672b4a",
        "outputId": "30200c57-4e98-4570-fba2-7e832736cccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.12/dist-packages (22.5)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e01f82"
      },
      "source": [
        "## افزودن مدیریت خطا\n",
        "\n",
        "### Subtask:\n",
        "افزودن مدیریت خطا برای جلوگیری از از کار افتادن ربات در صورت بروز مشکلات پیش‌بینی نشده در طول اجرای توابع مختلف.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2e2ec8"
      },
      "source": [
        "**Reasoning**:\n",
        "Add try...except blocks to the relevant functions and model loading sections to handle potential errors, log them, and send user-friendly messages, fulfilling the error handling requirement of the subtask.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNswmVDRSg1YuvLnjtmamfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e5e34f19d884885a3c38977b0705a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f1241acb0234a6486bc36922fcc90a8",
              "IPY_MODEL_ca4a185f8c4943979be80ec31613dce9",
              "IPY_MODEL_9eb60c187a3045c4a88734258fb01f04"
            ],
            "layout": "IPY_MODEL_c936a30f62e34fb1b8977f2f0cb4660d"
          }
        },
        "1f1241acb0234a6486bc36922fcc90a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7af069d3fded4f7986b556b85aa4afb5",
            "placeholder": "​",
            "style": "IPY_MODEL_2219741944524fc583db7558a6efbc42",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ca4a185f8c4943979be80ec31613dce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2775aeb495f4176b4684f460256a518",
            "max": 292,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_990218703b0b4ffbb07d148eca82d998",
            "value": 292
          }
        },
        "9eb60c187a3045c4a88734258fb01f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3959ace5492242d6b29a3bf91ac7aa99",
            "placeholder": "​",
            "style": "IPY_MODEL_833e410d4f7d4cc4982c242676e75baf",
            "value": " 292/292 [00:00&lt;00:00, 24.2kB/s]"
          }
        },
        "c936a30f62e34fb1b8977f2f0cb4660d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af069d3fded4f7986b556b85aa4afb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2219741944524fc583db7558a6efbc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2775aeb495f4176b4684f460256a518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990218703b0b4ffbb07d148eca82d998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3959ace5492242d6b29a3bf91ac7aa99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833e410d4f7d4cc4982c242676e75baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71987446a3d4206b49abcd98bb1874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95113e7ba22a442590a51dbcb009b6e2",
              "IPY_MODEL_87ef098897564d628ce320e649d70e28",
              "IPY_MODEL_d012be5b6b51473991fb258f41b1a264"
            ],
            "layout": "IPY_MODEL_f859d1b98b124b06b298b3564a05d719"
          }
        },
        "95113e7ba22a442590a51dbcb009b6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_993f420e78814ef399ae11ccd44e201e",
            "placeholder": "​",
            "style": "IPY_MODEL_611d9bb671934f7795a2c52042265f35",
            "value": "config.json: 100%"
          }
        },
        "87ef098897564d628ce320e649d70e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b55b5d4d87ac4e29bea6ca58749a4f12",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8acba16a03b4f9db6df413afa3614bb",
            "value": 565
          }
        },
        "d012be5b6b51473991fb258f41b1a264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a340bfe506e0413eba2478d11d652543",
            "placeholder": "​",
            "style": "IPY_MODEL_792cce6a91cb4fbdb39a829168b8d77a",
            "value": " 565/565 [00:00&lt;00:00, 47.7kB/s]"
          }
        },
        "f859d1b98b124b06b298b3564a05d719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993f420e78814ef399ae11ccd44e201e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611d9bb671934f7795a2c52042265f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55b5d4d87ac4e29bea6ca58749a4f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8acba16a03b4f9db6df413afa3614bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a340bfe506e0413eba2478d11d652543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792cce6a91cb4fbdb39a829168b8d77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66deb0ce078446fda52ad66ebfceb3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_993db2903cab423dbecb32a3dd4cb26c",
              "IPY_MODEL_614d1d10c5fd46b5ba467603dc52026e",
              "IPY_MODEL_293d45e33f7143548eccb114c799caa9"
            ],
            "layout": "IPY_MODEL_0f00bb9e0d2d43cfb22f9fd4238b7092"
          }
        },
        "993db2903cab423dbecb32a3dd4cb26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26f0a13cb5345dabe14aa299bef296b",
            "placeholder": "​",
            "style": "IPY_MODEL_43d440a6d0aa410d8d910238291aa1e8",
            "value": "vocab.txt: "
          }
        },
        "614d1d10c5fd46b5ba467603dc52026e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96f0dd17eb134f6d82ac13a948739dcb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1deb5b37670b40bcb050c19b913af3c2",
            "value": 1
          }
        },
        "293d45e33f7143548eccb114c799caa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0572e86c8da3443fa4b37e835bef21a4",
            "placeholder": "​",
            "style": "IPY_MODEL_3cdd65b8b4944583b6b1dedf2f120eb2",
            "value": " 426k/? [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "0f00bb9e0d2d43cfb22f9fd4238b7092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26f0a13cb5345dabe14aa299bef296b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d440a6d0aa410d8d910238291aa1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f0dd17eb134f6d82ac13a948739dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1deb5b37670b40bcb050c19b913af3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0572e86c8da3443fa4b37e835bef21a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cdd65b8b4944583b6b1dedf2f120eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e65ecd64c946c8a02c5fcce3efb5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79ba7084f0084958b0f2921379856899",
              "IPY_MODEL_6db966099fdf4364930a3a9283a20f2a",
              "IPY_MODEL_0853b2621cc44531a88d7e00417d812b"
            ],
            "layout": "IPY_MODEL_0c98c5414519401a8b662f06d2757e73"
          }
        },
        "79ba7084f0084958b0f2921379856899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b44407dc1234070874ff86dc8965f01",
            "placeholder": "​",
            "style": "IPY_MODEL_48e7d484489f4dcd97603fe2c4b0e9e8",
            "value": "tokenizer.json: "
          }
        },
        "6db966099fdf4364930a3a9283a20f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6eaf8fa2ad479da8d8be9bbac1237f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d67c3df01e4e4d92983f06c26560cde8",
            "value": 1
          }
        },
        "0853b2621cc44531a88d7e00417d812b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63d0e946289a490fadd14a73d9735604",
            "placeholder": "​",
            "style": "IPY_MODEL_b821ec5af006453a835f93c1bcd65292",
            "value": " 1.11M/? [00:00&lt;00:00, 34.3MB/s]"
          }
        },
        "0c98c5414519401a8b662f06d2757e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b44407dc1234070874ff86dc8965f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e7d484489f4dcd97603fe2c4b0e9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6eaf8fa2ad479da8d8be9bbac1237f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d67c3df01e4e4d92983f06c26560cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63d0e946289a490fadd14a73d9735604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b821ec5af006453a835f93c1bcd65292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2107f14ad64964890916f451af86f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d45f125223504cb39b07621cfd325fd4",
              "IPY_MODEL_b3cda01c19144229bb4bc0536ab7c578",
              "IPY_MODEL_06eb5668fc574a0dac13f8bbdb06680f"
            ],
            "layout": "IPY_MODEL_e5691d659a5049d996de42216f33ece7"
          }
        },
        "d45f125223504cb39b07621cfd325fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5eb436a23ab40d0951a8d947634e7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_9233c7b599824142a8d2cf1810c868a7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b3cda01c19144229bb4bc0536ab7c578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e044571c13e445409c0ae56031ba164c",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ab45e72c5843f88c8ab7b1224600dd",
            "value": 134
          }
        },
        "06eb5668fc574a0dac13f8bbdb06680f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262644632c0d453f9094271f0df88dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_af3b1ab6a34c436dab24382a91bfc5cc",
            "value": " 134/134 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "e5691d659a5049d996de42216f33ece7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5eb436a23ab40d0951a8d947634e7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9233c7b599824142a8d2cf1810c868a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e044571c13e445409c0ae56031ba164c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ab45e72c5843f88c8ab7b1224600dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "262644632c0d453f9094271f0df88dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3b1ab6a34c436dab24382a91bfc5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f507492379143e0a41317cd89d806f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a67bb6314f60489f9075e4cac75ff273",
              "IPY_MODEL_3d651afbb91845ea9ac17b5fe3276d6a",
              "IPY_MODEL_a4fa9c8a6038400086b1adfdd6bd2a55"
            ],
            "layout": "IPY_MODEL_dc72e05be2854a19b4868432eb058e24"
          }
        },
        "a67bb6314f60489f9075e4cac75ff273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffcd85dd0e94651aab6a15bafe3ee32",
            "placeholder": "​",
            "style": "IPY_MODEL_2f13ef86f6bf446e909e5cf122d76bf5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3d651afbb91845ea9ac17b5fe3276d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf136179ed324817b3af35cd2c8cfb5e",
            "max": 473451616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69103b7075e54b6a8175c4ceb8c5e903",
            "value": 473451616
          }
        },
        "a4fa9c8a6038400086b1adfdd6bd2a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc504f7824f346c398c69663e811872d",
            "placeholder": "​",
            "style": "IPY_MODEL_413708a77b024c57bae6c229a59a372c",
            "value": " 473M/473M [00:06&lt;00:00, 77.9MB/s]"
          }
        },
        "dc72e05be2854a19b4868432eb058e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffcd85dd0e94651aab6a15bafe3ee32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f13ef86f6bf446e909e5cf122d76bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf136179ed324817b3af35cd2c8cfb5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69103b7075e54b6a8175c4ceb8c5e903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc504f7824f346c398c69663e811872d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413708a77b024c57bae6c229a59a372c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341bea3430fc4eeaa943118768d58d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6a64b9a1274d6a803d8e57075a7d8e",
              "IPY_MODEL_44763f4b1745400ba706f9afcb9a2338",
              "IPY_MODEL_f9815cbf367d4f27bf0f7a8baa0a268f"
            ],
            "layout": "IPY_MODEL_a1512da8a42e40c9be4aef79967d7c27"
          }
        },
        "3a6a64b9a1274d6a803d8e57075a7d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e957510f5b4215ac60da1c8b94e0c6",
            "placeholder": "​",
            "style": "IPY_MODEL_bd3c992124fa4da899b712a9a22af9f5",
            "value": "model.safetensors: 100%"
          }
        },
        "44763f4b1745400ba706f9afcb9a2338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440fd6a5834f44acbb32c362fce749a4",
            "max": 473391424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0657445e0f3c409090bcb8cb9bb187a8",
            "value": 473391424
          }
        },
        "f9815cbf367d4f27bf0f7a8baa0a268f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a90fed65ed964ad48498acc661458fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_798a928097514c5fa8da79c9c266f858",
            "value": " 473M/473M [00:04&lt;00:00, 135MB/s]"
          }
        },
        "a1512da8a42e40c9be4aef79967d7c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e957510f5b4215ac60da1c8b94e0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3c992124fa4da899b712a9a22af9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440fd6a5834f44acbb32c362fce749a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0657445e0f3c409090bcb8cb9bb187a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a90fed65ed964ad48498acc661458fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798a928097514c5fa8da79c9c266f858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}